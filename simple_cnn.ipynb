{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_dl_config\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup cuda and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_dl_config()\n",
    "INPUT_FILE = conf['input_file']\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 150\n",
    "N_SPLITS = 5\n",
    "LR = 1e-3 \n",
    "RAND_SEED = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "torch.manual_seed(RAND_SEED) \n",
    "np.random.seed(RAND_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataarray(INPUT_FILE)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = data['patient_id'].values\n",
    "measurements = data.values\n",
    "\n",
    "# rename labels from 'bckg' and 'seiz' to 0 and 1\n",
    "unique_labels = np.unique(data['label'].values)\n",
    "labels_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "labels = np.array([labels_map[label] for label in data['label'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "splits = list(sgkf.split(X=measurements, y=labels, groups=patient_ids))\n",
    "train_idx, val_idx = splits[np.random.choice(N_SPLITS)]\n",
    "\n",
    "train_data, train_labels = measurements[train_idx], labels[train_idx]\n",
    "val_data, val_labels = measurements[val_idx], labels[val_idx]\n",
    "\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TUHDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].unsqueeze(0), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TUHDataset(train_data, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TUHDataset(val_data, val_labels)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cnn setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # input = batch_size x 1 x 19 x 5250\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=1) # output: batch_size x 6 x 15 x 5246\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=2) # output: batch_size x 6 x 7 x 2623\n",
    "\n",
    "        self.fc_input_size = 6 * 7 * 2623\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)  \n",
    "        x = self.fc1(x)\n",
    "\n",
    "        x = torch.sigmoid(x)  \n",
    "        return x\n",
    "\n",
    "model = SimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "# File to store best model metrics\n",
    "csv_filename = 'best_model_metrics.csv'\n",
    "\n",
    "# Write header to the CSV file\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Epoch', 'Val Loss', 'Val Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "\n",
    "    for data, labels in train_dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += ((outputs.squeeze() > 0.5) == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_val = 0\n",
    "    correct_val = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = (outputs.squeeze() > 0.5).float()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += ((outputs.squeeze() > 0.5) == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "    # Check if the current validation loss is the best we've seen so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "        # Save the model's state\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Best model saved at epoch {epoch+1} with validation loss: {val_loss:.4f} and validation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Save metrics to the CSV file\n",
    "        with open(csv_filename, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch+1, val_loss, val_accuracy, precision, recall, f1, roc_auc])\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{N_EPOCHS}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "net.eval()\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = net(data)\n",
    "        \n",
    "        # Convert outputs to binary predictions (0 or 1)\n",
    "        preds = (outputs.squeeze() > 0.5).long()\n",
    "        \n",
    "        # Store the predictions and true labels\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate standard metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "roc_auc = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(f'Test Precision: {precision}')\n",
    "print(f'Test Recall: {recall}')\n",
    "print(f'Test F1-Score: {f1}')\n",
    "print(f'Test ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
