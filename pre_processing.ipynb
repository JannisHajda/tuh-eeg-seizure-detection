{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import re\n",
    "from mne.preprocessing import ICA\n",
    "import xarray as xr\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "RAW_PATH = '/dhc/home/jannis.hajda/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/dhc/home/jannis.hajda/tuh-eeg-seizure-detection/data/processed'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 21\n",
    "OVERLAP = 10.5 \n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels_to_hemispheres(channels: list):\n",
    "    left_hemisphere = []\n",
    "    right_hemisphere = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel_number = re.search(r'\\d+', channel)\n",
    "        if channel_number is None:\n",
    "            continue\n",
    "        \n",
    "        if int(channel_number.group()) % 2 == 0:\n",
    "            right_hemisphere.append(channel)\n",
    "        else:\n",
    "            left_hemisphere.append(channel)\n",
    "    \n",
    "    return left_hemisphere, right_hemisphere\n",
    "\n",
    "LEFT_HEMISPHERE, RIGHT_HEMISPHERE = split_channels_to_hemispheres(CHANNELS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start = float(parts[1])\n",
    "            stop = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"start\": start,\n",
    "                \"stop\": stop,\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13556c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_windows():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"event_index\", \"start\", \"stop\", \"label\"]\n",
    "    data = []\n",
    "    \n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    \n",
    "    for root, _, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".edf\"):\n",
    "                continue\n",
    "            \n",
    "            rel_path = os.path.relpath(root, edf_path)\n",
    "            parts = rel_path.split(\"/\")\n",
    "            \n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "        \n",
    "            set_name, patient_id, session_id, configuration = parts\n",
    "            \n",
    "            if configuration not in CONFIGURATIONS:\n",
    "                continue\n",
    "        \n",
    "            recording_path = os.path.join(root, file)\n",
    "            recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "            annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "            \n",
    "            if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                continue\n",
    "            \n",
    "            events = extract_events_from_annotations(annotation_path)\n",
    "            \n",
    "            for i, event in events.iterrows():\n",
    "                start, stop, label = event.loc[[\"start\", \"stop\", \"label\"]]\n",
    "                duration = stop - start\n",
    "\n",
    "                if duration < WINDOW_LENGTH:\n",
    "                    continue\n",
    "\n",
    "                while start + WINDOW_LENGTH < stop:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"event_index\": i,\n",
    "                        \"start\": start,\n",
    "                        \"stop\": start + WINDOW_LENGTH,\n",
    "                        \"label\": label,\n",
    "                    })\n",
    "                    \n",
    "                    start += WINDOW_LENGTH - OVERLAP\n",
    "\n",
    "    return pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d59ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = load_windows()\n",
    "windows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7196e7c",
   "metadata": {},
   "source": [
    "### undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seiz_windows = windows[windows[\"label\"] == \"seiz\"]\n",
    "bckg_windows = windows[windows[\"label\"] == \"bckg\"]\n",
    "\n",
    "print(\"Seizure windows:\", len(seiz_windows))\n",
    "print(\"Background windows:\", len(bckg_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(bckg_windows) > len(seiz_windows):\n",
    "    bckg_windows = bckg_windows.sample(n=len(seiz_windows))\n",
    "else:\n",
    "    seiz_windows = seiz_windows.sample(n=len(bckg_windows))\n",
    "\n",
    "windows = pd.concat([seiz_windows, bckg_windows])\n",
    "windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6baf8",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfbf75e5c37dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_powerline_noise(raw):\n",
    "    powerline_noises = [60]\n",
    "\n",
    "    for freq in powerline_noises:\n",
    "        raw.notch_filter(freqs=freq)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth_filter(raw):\n",
    "    iir_params = dict(order=4, ftype='butter')\n",
    "    raw.filter(0.5, 50, method='iir', iir_params=iir_params)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_raw(raw, start, stop):\n",
    "    \"\"\"Crops the raw data based on the onset and duration, handling edge cases.\"\"\"\n",
    "    if stop > raw.times[-1]:\n",
    "        if stop - 1 / raw.info[\"sfreq\"] == raw.times[-1]:\n",
    "            return raw.copy().crop(start, raw.times[-1], include_tmax=True), True\n",
    "        else:\n",
    "            return None, False\n",
    "    else:\n",
    "        return raw.copy().crop(start, stop, include_tmax=False), True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da3dd8",
   "metadata": {},
   "source": [
    "### process recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recording(recording_path, recording_windows: pd.DataFrame):\n",
    "    try:\n",
    "        \n",
    "        raw_recording = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        raw_recording.set_meas_date(None)\n",
    "        \n",
    "        raw_recording = remove_powerline_noise(raw_recording)\n",
    "        raw_recording = butterworth_filter(raw_recording)\n",
    "        raw_recording = raw_recording.resample(SAMPLING_FREQ)\n",
    "\n",
    "        raw_windows = []\n",
    "\n",
    "        for _, window in recording_windows.iterrows():\n",
    "            patient_id, label, start, stop = window[[\"patient_id\", \"label\", \"start\", \"stop\"]]\n",
    "            raw_window, valid = crop_raw(raw_recording, start, stop)\n",
    "            if not valid:\n",
    "                continue\n",
    "        \n",
    "            channel_data = raw_window.get_data()\n",
    "\n",
    "            raw_windows.append({\n",
    "                \"patient_id\": patient_id,\n",
    "                \"channel_data\": channel_data,\n",
    "                \"label\": label, \n",
    "            })\n",
    "\n",
    "            raw_window.close()\n",
    "        \n",
    "        raw_recording.close()\n",
    "\n",
    "        # create xarray dataset from raw windows\n",
    "        channel_data = np.stack([window[\"channel_data\"] for window in raw_windows])\n",
    "        labels = np.array([window[\"label\"] for window in raw_windows])\n",
    "        patient_id = np.array([window[\"patient_id\"] for window in raw_windows])\n",
    "\n",
    "        data = xr.DataArray(channel_data, dims=(\"window\", \"channel\", \"time\"), coords={\n",
    "            \"patient_id\": (\"window\", patient_id),\n",
    "            \"label\": (\"window\", labels),\n",
    "            \"channel\": CHANNELS,\n",
    "        })\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process recording {recording_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recordings_parallel(recordings, num_processes=None):\n",
    "    manager = mp.Manager()\n",
    "    queue = manager.Queue()\n",
    "\n",
    "    if num_processes is None:\n",
    "        num_processes = mp.cpu_count()\n",
    "    \n",
    "    def listener(q, total):\n",
    "        pbar = tqdm(total=total, desc=\"Processing recordings\")\n",
    "        for _ in range(total):\n",
    "            q.get()\n",
    "            pbar.update()\n",
    "            pbar.refresh()\n",
    "        pbar.close()\n",
    "\n",
    "    def callback(_):\n",
    "        queue.put(1)    \n",
    "\n",
    "    def error_callback(e):\n",
    "        print(f\"Error: {e}\")\n",
    "        queue.put(1)\n",
    "\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        print(\"Starting parallel processing...\")\n",
    "        listener_process = mp.Process(target=listener, args=(queue, len(recordings)))\n",
    "        listener_process.start()\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # Process recordings\n",
    "        for recording_path, recording_windows in recordings:\n",
    "            result = pool.apply_async(process_recording, args=(recording_path, recording_windows), callback=callback, error_callback=error_callback)\n",
    "            results.append(result)\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        listener_process.join()\n",
    "\n",
    "        results = [r.get() for r in results]\n",
    "        results = [r for r in results if r is not None]\n",
    "\n",
    "        print(\"Combining results...\")\n",
    "\n",
    "        data = xr.concat(results, dim=\"window\")\n",
    "\n",
    "        print(\"Finished processing recordings.\")\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = windows.groupby(\"recording_path\")\n",
    "data = process_recordings_parallel(recordings, num_processes=24)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bab82",
   "metadata": {},
   "source": [
    "### normalize data across channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "    min_vals = data.min(dim=\"window\")\n",
    "    max_vals = data.max(dim=\"window\")\n",
    "    normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df68a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = min_max_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639456d2",
   "metadata": {},
   "source": [
    "### write preprocessed data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_netcdf(os.path.join(OUTPUT_PATH, \"windows_normalized.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05ed1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
