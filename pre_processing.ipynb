{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from mne.io.edf.edf import RawEDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f482002e920196",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUH_EEG_SEIZURE_CORPUS = \"/Users/jannis/Git/tuh-eeg-seizure-detection/data/raw\"\n",
    "OUTPUT = \"/Users/jannis/Git/tuh-eeg-seizure-detection/data/preprocessed\"\n",
    "\n",
    "SAMPLING_FREQUENCY = 250\n",
    "WINDOW_LENGTH = 1\n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c97c7af5cf180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recording:\n",
    "    path: str\n",
    "    \n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "    \n",
    "    def load(self, channels: [str] = CHANNELS):\n",
    "        raw = mne.io.read_raw_edf(self.path, preload=True)\n",
    "        raw.pick(channels)\n",
    "        \n",
    "        annotations = self._parse_annotations()\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        return raw\n",
    "            \n",
    "    def _parse_annotations(self):\n",
    "        annotation_file = self.path.replace(\".edf\", \".csv_bi\")\n",
    "        annotations: [str] = []\n",
    "        \n",
    "        with open(annotation_file, \"r\") as file:\n",
    "            for line in file:\n",
    "                annotations.append(line)\n",
    "        \n",
    "        annotations = annotations[6:]\n",
    "        \n",
    "        onset = []\n",
    "        duration = []\n",
    "        description = []\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            parts = annotation.split(\",\")\n",
    "            start = float(parts[1])\n",
    "            end = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            onset.append(start)\n",
    "            duration.append(end - start)\n",
    "            description.append(label)\n",
    "            \n",
    "        return mne.Annotations(onset, duration, description)\n",
    "        \n",
    "class Session:\n",
    "    session_id: str\n",
    "    recordings: [Recording]\n",
    "    configuration: str\n",
    "    \n",
    "    def __init__(self, session_id: str, configuration: str):\n",
    "        self.session_id = session_id\n",
    "        self.configuration = configuration\n",
    "        self.recordings = []\n",
    "        \n",
    "    def add_recording(self, recording: Recording):\n",
    "        self.recordings.append(recording)\n",
    "        \n",
    "class Patient:\n",
    "    patient_id: str\n",
    "    sessions: [Session]\n",
    "    \n",
    "    def __init__(self, patient_id: str):\n",
    "        self.patient_id = patient_id\n",
    "        self.sessions = []\n",
    "        \n",
    "    def add_session(self, session: Session):\n",
    "        self.sessions.append(session)\n",
    "        \n",
    "class Dataset:\n",
    "    patients: [Patient]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patients = []\n",
    "        \n",
    "    def add_patient(self, patient: Patient):\n",
    "        self.patients.append(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bf6d6234ba043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(set_name: str, configurations: [str] = CONFIGURATIONS):\n",
    "    path = f\"{TUH_EEG_SEIZURE_CORPUS}/edf/{set_name}\"\n",
    "    dataset = Dataset()\n",
    "    \n",
    "    for patient_id in os.listdir(path):\n",
    "        patient_path = f\"{path}/{patient_id}\"\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        \n",
    "        patient = Patient(patient_id)\n",
    "        \n",
    "        for session_id in os.listdir(patient_path):\n",
    "            session_path = f\"{patient_path}/{session_id}\"\n",
    "            if not os.path.isdir(session_path):\n",
    "                continue\n",
    "            \n",
    "            session = Session(session_id, set_name)\n",
    "            \n",
    "            for configuration in os.listdir(session_path):\n",
    "                configuration_path = f\"{session_path}/{configuration}\"\n",
    "                if not os.path.isdir(configuration_path) or configuration not in configurations:\n",
    "                    continue\n",
    "                    \n",
    "                session.configuration = configuration\n",
    "                \n",
    "                for recording_id in os.listdir(configuration_path):\n",
    "                    recording_path = f\"{configuration_path}/{recording_id}\"\n",
    "                    if not os.path.isfile(recording_path) or not recording_path.endswith(\".edf\"):\n",
    "                        continue\n",
    "                    \n",
    "                    recording = Recording(recording_path)\n",
    "                    session.add_recording(recording) \n",
    "            \n",
    "            if len(session.recordings) > 0:\n",
    "                patient.add_session(session)\n",
    "            \n",
    "        if len(patient.sessions) > 0:\n",
    "            dataset.add_patient(patient)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8ec7fb6208516",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = load_dataset(\"dev\")\n",
    "eval_dataset = load_dataset(\"eval\")\n",
    "train_dataset = load_dataset(\"train\")\n",
    "print(f\"Dev set: {len(dev_dataset.patients)}\")\n",
    "print(f\"Eval set: {len(eval_dataset.patients)}\")\n",
    "print(f\"Train set: {len(train_dataset.patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e38caf3c4b3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all datasets\n",
    "dataset = Dataset()\n",
    "dataset.patients = dev_dataset.patients + eval_dataset.patients + train_dataset.patients\n",
    "print(f\"Combined set: {len(dataset.patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3d58d5a33e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find patient with id aaaaamnk\n",
    "patient = None\n",
    "for p in dataset.patients:\n",
    "    if p.patient_id == \"aaaaamnk\":\n",
    "        patient = p\n",
    "        break\n",
    "\n",
    "print(f\"Patient {patient.patient_id} has {len(patient.sessions)} sessions\")\n",
    "sess = patient.sessions[0]\n",
    "rec = sess.recordings[0]\n",
    "raw = mne.io.read_raw_edf(rec.path, preload=True)\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20be4635233a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 patients, skip first 10 \n",
    "patients = dataset.patients[100:120]\n",
    "\n",
    "for patient in patients:\n",
    "    for session in patient.sessions:\n",
    "        for recording in session.recordings:\n",
    "            recording_name = recording.path.split(\"/\")[-1].replace(\".edf\", \"\")\n",
    "            recording_name = recording_name.split(\"_\")[-1]\n",
    "            \n",
    "            raw = recording.load(CHANNELS)\n",
    "            raw.resample(SAMPLING_FREQUENCY)\n",
    "            \n",
    "            seizure_samples = []\n",
    "            non_seizure_samples = []\n",
    "            \n",
    "            for i in range(len(raw.annotations)):\n",
    "                onset = raw.annotations[i][\"onset\"]\n",
    "                duration = raw.annotations[i][\"duration\"]\n",
    "                description = raw.annotations[i][\"description\"]\n",
    "                \n",
    "                # prevent overlong \n",
    "                if onset + duration > raw.times[-1]:\n",
    "                    duration = raw.times[-1] - onset\n",
    "                \n",
    "                sample = raw.copy().crop(onset, onset + duration)\n",
    "                \n",
    "                if description == \"bckg\":\n",
    "                    non_seizure_samples.append(sample)\n",
    "                else:\n",
    "                    seizure_samples.append(sample)\n",
    "                    \n",
    "            if len(seizure_samples) == 0 and len(non_seizure_samples) == 0:\n",
    "                continue\n",
    "            \n",
    "            os.makedirs(f\"{OUTPUT}/{patient.patient_id}/seizures\", exist_ok=True)\n",
    "            os.makedirs(f\"{OUTPUT}/{patient.patient_id}/non_seizures\", exist_ok=True)\n",
    "            \n",
    "            for sample in seizure_samples:\n",
    "                num_of_epochs = int(sample.times[-1] / WINDOW_LENGTH)\n",
    "                for i in range(num_of_epochs):\n",
    "                    epoch_path = f\"{OUTPUT}/{patient.patient_id}/seizures/{session.session_id}_{recording_name}_{i}_raw.fif\"\n",
    "                   \n",
    "                    # check if epoch already exists\n",
    "                    if os.path.isfile(epoch_path):\n",
    "                        continue\n",
    "                    \n",
    "                    start = i * WINDOW_LENGTH\n",
    "                    end = start + WINDOW_LENGTH\n",
    "                    epoch = sample.copy().crop(start, end)\n",
    "                    \n",
    "                    # sometimes measurement date is not set correctly -> we don't need it, so just set it to now\n",
    "                    epoch.set_meas_date(datetime.datetime.now(datetime.UTC))\n",
    "                    \n",
    "                    epoch.save(epoch_path, overwrite=False)\n",
    "                    \n",
    "            for sample in non_seizure_samples:\n",
    "                num_of_epochs = int(sample.times[-1] / WINDOW_LENGTH)\n",
    "                for i in range(num_of_epochs):\n",
    "                    epoch_path = f\"{OUTPUT}/{patient.patient_id}/non_seizures/{session.session_id}_{recording_name}_{i}_raw.fif\"\n",
    "                    \n",
    "                    # check if epoch already exists\n",
    "                    if os.path.isfile(epoch_path):\n",
    "                        continue\n",
    "                    \n",
    "                    start = i * WINDOW_LENGTH\n",
    "                    end = start + WINDOW_LENGTH\n",
    "                    epoch = sample.copy().crop(start, end)\n",
    "                    \n",
    "                    # sometimes measurement date is not set correctly -> we don't need it, so just set it to now\n",
    "                    epoch.set_meas_date(datetime.datetime.now(datetime.UTC))\n",
    "                    \n",
    "                    epoch.save(epoch_path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b1c0cfab071fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/Users/jannis/Git/tuh-eeg-seizure-detection/data/preprocessed/aaaaaiij/seizures\"\n",
    "seizures = []\n",
    "for file in os.listdir(p):\n",
    "    file_path = os.path.join(p, file)\n",
    "    \n",
    "    if not os.path.isfile(file_path) or not file_path.endswith(\".fif\"):\n",
    "        continue\n",
    "        \n",
    "    seizures.append(file_path)\n",
    "\n",
    "raw = mne.io.read_raw_fif(seizures[2], preload=True)\n",
    "raw.plot()\n",
    "\n",
    "non_seizures = []\n",
    "p = \"/Users/jannis/Git/tuh-eeg-seizure-detection/data/preprocessed/aaaaamnk/non_seizures\"\n",
    "for file in os.listdir(p):\n",
    "    file_path = os.path.join(p, file)\n",
    "    \n",
    "    if not os.path.isfile(file_path) or not file_path.endswith(\".fif\"):\n",
    "        continue\n",
    "        \n",
    "    non_seizures.append(file_path)\n",
    "    \n",
    "raw = mne.io.read_raw_fif(non_seizures[2], preload=True)\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76feca130a4ced7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775e57683c7ca5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
