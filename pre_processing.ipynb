{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "RAW_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 30\n",
    "OVERLAP = 10 \n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc1c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels_to_hemispheres(channels: list):\n",
    "    left_hemisphere = []\n",
    "    right_hemisphere = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel_number = re.search(r'\\d+', channel)\n",
    "        if channel_number is None:\n",
    "            continue\n",
    "        \n",
    "        if int(channel_number.group()) % 2 == 0:\n",
    "            right_hemisphere.append(channel)\n",
    "        else:\n",
    "            left_hemisphere.append(channel)\n",
    "    \n",
    "    return left_hemisphere, right_hemisphere\n",
    "\n",
    "LEFT_HEMISPHERE, RIGHT_HEMISPHERE = split_channels_to_hemispheres(CHANNELS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start = float(parts[1])\n",
    "            stop = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"start\": start,\n",
    "                \"stop\": stop,\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13556c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>configuration</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>recording_path</th>\n",
       "      <th>event_index</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s011_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>689.8535</td>\n",
       "      <td>719.8535</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s011_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>709.8535</td>\n",
       "      <td>739.8535</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s001_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>114.9989</td>\n",
       "      <td>144.9989</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s001_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>134.9989</td>\n",
       "      <td>164.9989</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s001_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>154.9989</td>\n",
       "      <td>184.9989</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s007_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>990.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s007_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>980.0000</td>\n",
       "      <td>1010.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s007_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>1030.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s007_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t015</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0166</td>\n",
       "      <td>255.0166</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaanme</td>\n",
       "      <td>s007_2014</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t015</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0166</td>\n",
       "      <td>275.0166</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2159 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        set patient_id session_id configuration recording_id  \\\n",
       "0     train   aaaaanme  s011_2014     01_tcp_ar         t000   \n",
       "1     train   aaaaanme  s011_2014     01_tcp_ar         t000   \n",
       "2     train   aaaaanme  s001_2012     01_tcp_ar         t000   \n",
       "3     train   aaaaanme  s001_2012     01_tcp_ar         t000   \n",
       "4     train   aaaaanme  s001_2012     01_tcp_ar         t000   \n",
       "...     ...        ...        ...           ...          ...   \n",
       "2154  train   aaaaanme  s007_2014     01_tcp_ar         t008   \n",
       "2155  train   aaaaanme  s007_2014     01_tcp_ar         t008   \n",
       "2156  train   aaaaanme  s007_2014     01_tcp_ar         t008   \n",
       "2157  train   aaaaanme  s007_2014     01_tcp_ar         t015   \n",
       "2158  train   aaaaanme  s007_2014     01_tcp_ar         t015   \n",
       "\n",
       "                                         recording_path  event_index  \\\n",
       "0     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "1     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "2     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "3     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "4     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "...                                                 ...          ...   \n",
       "2154  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "2155  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "2156  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "2157  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "2158  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   \n",
       "\n",
       "          start       stop label  \n",
       "0      689.8535   719.8535  seiz  \n",
       "1      709.8535   739.8535  seiz  \n",
       "2      114.9989   144.9989  seiz  \n",
       "3      134.9989   164.9989  seiz  \n",
       "4      154.9989   184.9989  seiz  \n",
       "...         ...        ...   ...  \n",
       "2154   960.0000   990.0000  bckg  \n",
       "2155   980.0000  1010.0000  bckg  \n",
       "2156  1000.0000  1030.0000  bckg  \n",
       "2157   225.0166   255.0166  seiz  \n",
       "2158   245.0166   275.0166  seiz  \n",
       "\n",
       "[2159 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_windows():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"event_index\", \"start\", \"stop\", \"label\"]\n",
    "    data = []\n",
    "    \n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    \n",
    "    for root, _, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".edf\"):\n",
    "                continue\n",
    "            \n",
    "            rel_path = os.path.relpath(root, edf_path)\n",
    "            parts = rel_path.split(\"/\")\n",
    "            \n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "        \n",
    "            set_name, patient_id, session_id, configuration = parts\n",
    "            \n",
    "            if configuration not in CONFIGURATIONS:\n",
    "                continue\n",
    "        \n",
    "            recording_path = os.path.join(root, file)\n",
    "            recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "            annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "            \n",
    "            if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                continue\n",
    "            \n",
    "            events = extract_events_from_annotations(annotation_path)\n",
    "            \n",
    "            for i, event in events.iterrows():\n",
    "                start, stop, label = event.loc[[\"start\", \"stop\", \"label\"]]\n",
    "                duration = stop - start\n",
    "\n",
    "                if duration < WINDOW_LENGTH:\n",
    "                    continue\n",
    "\n",
    "                while start + WINDOW_LENGTH < stop:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"event_index\": i,\n",
    "                        \"start\": start,\n",
    "                        \"stop\": start + WINDOW_LENGTH,\n",
    "                        \"label\": label,\n",
    "                    })\n",
    "                    \n",
    "                    start += WINDOW_LENGTH - OVERLAP\n",
    "\n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "windows = load_windows()\n",
    "windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7196e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### undersample windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5af89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seizure windows: 155\n",
      "Background windows: 2004\n"
     ]
    }
   ],
   "source": [
    "seiz_windows = windows[windows[\"label\"] == \"seiz\"]\n",
    "bckg_windows = windows[windows[\"label\"] == \"bckg\"]\n",
    "\n",
    "print(\"Seizure windows:\", len(seiz_windows))\n",
    "print(\"Background windows:\", len(bckg_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23dd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample majority class\n",
    "bckg_windows = bckg_windows.sample(n=len(seiz_windows), random_state=42)\n",
    "windows = pd.concat([seiz_windows, bckg_windows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    mean = np.mean(coeffs)\n",
    "    median = np.median(coeffs)\n",
    "    std = np.std(coeffs)\n",
    "    variance = np.var(coeffs)\n",
    "    skew = sp.stats.skew(coeffs)\n",
    "    kurtosis = sp.stats.kurtosis(coeffs)\n",
    "    rms = np.sqrt(np.mean(coeffs ** 2))\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"variance\": variance,\n",
    "        \"std\": std,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "        \"rms\": rms\n",
    "    }\n",
    "    \n",
    "def extract_wavelet_features(channel_data: np.ndarray ) -> dict[str, float]:\n",
    "    a5, d5, d4, d3, d2, d1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    \n",
    "    wavelet_features = {f\"{coeff}_{stat}\": value \n",
    "                        for coeff, data in zip([\"a5\", \"d5\", \"d4\", \"d3\"], [a5, d5, d4, d3])\n",
    "                        for stat, value in calc_coeffs_features(data).items()}\n",
    "    \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37cbbd7296b02baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_band_power(channel_data, sfreq=SAMPLING_FREQ, n_fft=256) -> dict[str, float]:\n",
    "    frequency_bands = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 7),\n",
    "        \"alpha\": (7, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 50)\n",
    "    }\n",
    "\n",
    "    band_powers = {}\n",
    "\n",
    "    n_fft = min(n_fft, sfreq)\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(channel_data, sfreq=sfreq, n_fft=n_fft, fmin=0.5, fmax=50)\n",
    "\n",
    "    # Calculate power within each frequency band\n",
    "    for band, (fmin, fmax) in frequency_bands.items():\n",
    "        # Find indices of frequencies within the band\n",
    "        band_indices = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "\n",
    "        # Sum the power spectral density values within the band\n",
    "        band_power = np.sum(psds[band_indices])\n",
    "\n",
    "        band_powers[band] = band_power\n",
    "\n",
    "    return band_powers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e9161530113c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_power_ratios(band_powers : dict[str, float]) -> dict[str, float]:\n",
    "    alpha_beta_ratio = band_powers[\"alpha\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_beta_ratio = band_powers[\"theta\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_alpha_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / (band_powers[\"beta\"] + band_powers[\"alpha\"]) if (band_powers[\"beta\"] + band_powers[\"alpha\"]) != 0 else np.nan\n",
    "    alpha_theta_ratio = band_powers[\"alpha\"] / band_powers[\"theta\"] if band_powers[\"theta\"] != 0 else np.nan\n",
    "    theta_alpha_ratio = band_powers[\"theta\"] / band_powers[\"alpha\"] if band_powers[\"alpha\"] != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        \"alpha_beta_ratio\": alpha_beta_ratio,\n",
    "        \"theta_beta_ratio\": theta_beta_ratio,\n",
    "        \"theta_alpha_beta_ratio\": theta_alpha_beta_ratio,\n",
    "        \"theta_alpha_beta_alpha_ratio\": theta_alpha_beta_alpha_ratio,\n",
    "        \"alpha_theta_ratio\": alpha_theta_ratio,\n",
    "        \"theta_alpha_ratio\": theta_alpha_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a304d0cefaf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_band_powers(band_powers):\n",
    "    avg_band_powers = {}\n",
    "    for band in band_powers[0].keys():\n",
    "        avg_band_powers[band] = np.mean([bp[band] for bp in band_powers])\n",
    "        \n",
    "    return avg_band_powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb734f78e39421c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_asymmetry(band_powers):\n",
    "    left_power = 0\n",
    "    right_power = 0\n",
    "    \n",
    "    for i, channel in enumerate(CHANNELS):\n",
    "        if channel in LEFT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                left_power += power\n",
    "        elif channel in RIGHT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                right_power += power\n",
    "            \n",
    "    left_power = np.log(left_power) if left_power != 0 else 0\n",
    "    right_power = np.log(right_power) if right_power != 0 else 0\n",
    "    \n",
    "    asymmetry = left_power - right_power\n",
    "    return asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6baf8",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8cfbf75e5c37dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_powerline_noise(raw):\n",
    "    powerline_noises = [50, 60]\n",
    "\n",
    "    for freq in powerline_noises:\n",
    "        raw.notch_filter(freqs=freq)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269b9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth_filter(raw):\n",
    "    iir_params = dict(order=4, ftype='butter')\n",
    "    raw.filter(0.5, 50, method='iir', iir_params=iir_params)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2a1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dac3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_raw_event(raw, start, stop):\n",
    "    \"\"\"Crops the raw data based on the onset and duration, handling edge cases.\"\"\"\n",
    "    if stop > raw.times[-1]:\n",
    "        if stop - 1 / raw.info[\"sfreq\"] == raw.times[-1]:\n",
    "            return raw.copy().crop(start, raw.times[-1], include_tmax=True), True\n",
    "        else:\n",
    "            return None, False\n",
    "    else:\n",
    "        return raw.copy().crop(start, stop, include_tmax=False), True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1e8e8",
   "metadata": {},
   "source": [
    "### process windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_windows(windows: pd.DataFrame):\n",
    "    corrupted = []\n",
    "    features = []\n",
    "\n",
    "    recordings = windows.groupby(\"recording_path\")\n",
    "    \n",
    "    for recording_path, recording in recordings:\n",
    "        raw_recording = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        raw_recording.set_meas_date(None)\n",
    "\n",
    "        for _, window in recording.iterrows():\n",
    "            patient_id, session_id, recording_id, event_index, start, stop, label = window.loc[[\"patient_id\", \"session_id\", \"recording_id\", \"event_index\", \"start\", \"stop\", \"label\"]]\n",
    "\n",
    "            raw_window, success = crop_raw_event(raw_recording, start, stop)\n",
    "            if not success:\n",
    "                print(f\"Failed to crop event {event_index} in recording {recording_id} for patient {patient_id} and session {session_id}.\")\n",
    "                corrupted.append((patient_id, session_id, recording_id))\n",
    "                continue\n",
    "\n",
    "            raw_window = raw_window.resample(SAMPLING_FREQ)\n",
    "            raw_window = butterworth_filter(raw_window)\n",
    "            raw_window = remove_powerline_noise(raw_window)\n",
    "\n",
    "            channels = raw_window.info[\"ch_names\"]\n",
    "\n",
    "            band_powers = []\n",
    "            window_features = {}\n",
    "\n",
    "            for i, channel in enumerate(channels):\n",
    "                channel_data, _ = raw_window[i]\n",
    "                channel_data = channel_data.flatten()\n",
    "                \n",
    "                channel_data = min_max_normalization(channel_data)\n",
    "\n",
    "                wavelet_features = extract_wavelet_features(channel_data)\n",
    "                for key, value in wavelet_features.items():\n",
    "                    window_features[f\"{channel}_{key}\"] = value\n",
    "\n",
    "                band_power = extract_band_power(channel_data)\n",
    "                band_powers.append(band_power)\n",
    "            \n",
    "            avg_band_powers = calc_avg_band_powers(band_powers)\n",
    "            power_ratios = calc_power_ratios(avg_band_powers)\n",
    "            \n",
    "            asymmetry = calc_asymmetry(band_powers)\n",
    "            \n",
    "            window_features.update({\n",
    "                \"patient_id\": patient_id,\n",
    "                \"session_id\": session_id,\n",
    "                \"recording_id\": recording_id,\n",
    "                \"recording_path\": recording_path,\n",
    "                \"event_index\": event_index,\n",
    "                \"asymmetry\": asymmetry,\n",
    "                \"label\": label,\n",
    "                \"start\": start,\n",
    "                \"stop\": stop\n",
    "            })\n",
    "            \n",
    "            window_features = {**window_features, **avg_band_powers, **power_ratios}\n",
    "            features.append(window_features)\n",
    "                \n",
    "            raw_window.close()\n",
    "            \n",
    "        raw_recording.close()\n",
    "        \n",
    "    return pd.DataFrame(features), corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [57:34<00:00, 3454.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_patient_windows(patient_windows):\n",
    "    patient_id = patient_windows[\"patient_id\"].iloc[0]\n",
    "    \n",
    "    try:\n",
    "        features, corrupted = process_windows(patient_windows)\n",
    "\n",
    "        if patient_windows.shape[0] != features.shape[0]:\n",
    "            print(f\"Window mismatch for patient {patient_id}\")\n",
    "\n",
    "        if corrupted:\n",
    "            print(f\"Corrupted patient {patient_id}\")\n",
    "\n",
    "        return patient_id, features, corrupted\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing patient {patient_id}: {e}\")\n",
    "        return patient_id, None, None\n",
    "def update_progress(result):\n",
    "    pbar.update()\n",
    "\n",
    "def process_windows_parallel(windows, num_processes=None):\n",
    "    patient_ids = windows[\"patient_id\"].unique()\n",
    "    \n",
    "    if num_processes is None:\n",
    "        num_processes = mp.cpu_count()\n",
    "\n",
    "    with mp.Pool(num_processes) as pool:\n",
    "        global pbar\n",
    "        pbar = tqdm(total=len(patient_ids))\n",
    "        results = []\n",
    "\n",
    "        for patient_id in patient_ids:\n",
    "            patient_windows = windows[windows[\"patient_id\"] == patient_id]\n",
    "            result = pool.apply_async(process_patient_windows, args=(patient_windows,), callback=update_progress, error_callback=update_progress)\n",
    "            results.append(result)\n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        processed_results = [result.get() for result in results]\n",
    "    \n",
    "    for patient_id, features, corrupted in processed_results:\n",
    "        if features is not None:\n",
    "            # Handle the features and corrupted data as needed\n",
    "            pass\n",
    "\n",
    "process_windows_parallel(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882827c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
