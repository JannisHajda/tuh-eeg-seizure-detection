{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "RAW_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 30\n",
    "OVERLAP = 10 \n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc1c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels_to_hemispheres(channels: list):\n",
    "    left_hemisphere = []\n",
    "    right_hemisphere = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel_number = re.search(r'\\d+', channel)\n",
    "        if channel_number is None:\n",
    "            continue\n",
    "        \n",
    "        if int(channel_number.group()) % 2 == 0:\n",
    "            right_hemisphere.append(channel)\n",
    "        else:\n",
    "            left_hemisphere.append(channel)\n",
    "    \n",
    "    return left_hemisphere, right_hemisphere\n",
    "\n",
    "LEFT_HEMISPHERE, RIGHT_HEMISPHERE = split_channels_to_hemispheres(CHANNELS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6fac45f4b713",
   "metadata": {},
   "source": [
    "#### extract events from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start_time = float(parts[1])\n",
    "            stop_time = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"onset\": start_time,\n",
    "                \"duration\": stop_time - start_time\n",
    "            })\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40cd685fe2e87a",
   "metadata": {},
   "source": [
    "#### load the TUH EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d687c5955aa64b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>configuration</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>recording_path</th>\n",
       "      <th>label</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t000</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>bckg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>300.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t004</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>bckg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>601.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>bckg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1224.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t006</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>seiz</td>\n",
       "      <td>2352.0111</td>\n",
       "      <td>35.9867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>bckg</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>300.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      set patient_id session_id configuration recording_id  \\\n",
       "66  train   aaaaajrj  s006_2012     01_tcp_ar         t000   \n",
       "67  train   aaaaajrj  s006_2012     01_tcp_ar         t004   \n",
       "68  train   aaaaajrj  s006_2012     01_tcp_ar         t008   \n",
       "69  train   aaaaajrj  s006_2012     01_tcp_ar         t006   \n",
       "70  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "\n",
       "                                       recording_path label      onset  \\\n",
       "66  /home/nis/Git/tuh-eeg-seizure-detection/data/r...  bckg     0.0000   \n",
       "67  /home/nis/Git/tuh-eeg-seizure-detection/data/r...  bckg     0.0000   \n",
       "68  /home/nis/Git/tuh-eeg-seizure-detection/data/r...  bckg     0.0000   \n",
       "69  /home/nis/Git/tuh-eeg-seizure-detection/data/r...  seiz  2352.0111   \n",
       "70  /home/nis/Git/tuh-eeg-seizure-detection/data/r...  bckg     0.0000   \n",
       "\n",
       "     duration  \n",
       "66   300.0000  \n",
       "67   601.0000  \n",
       "68  1224.0000  \n",
       "69    35.9867  \n",
       "70   300.0000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_tuh_eeg():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"label\", \"onset\", \"duration\"]\n",
    "    data = []\n",
    "    \n",
    "    # get all edf files in RAW/edf\n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\"):\n",
    "                rel_path = os.path.relpath(root, edf_path)\n",
    "                parts = rel_path.split(\"/\")\n",
    "                \n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "                    \n",
    "                set_name, patient_id, session_id, configuration = parts\n",
    "                \n",
    "                if configuration not in CONFIGURATIONS:\n",
    "                    continue\n",
    "                \n",
    "                recording_path = os.path.join(root, file)\n",
    "                recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "                annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "                \n",
    "                if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                    continue\n",
    "                \n",
    "                events = extract_events_from_annotations(annotation_path)\n",
    "                for event in events:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"label\": event[\"label\"],\n",
    "                        \"onset\": event[\"onset\"],\n",
    "                        \"duration\": event[\"duration\"]\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "data = load_tuh_eeg()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13556c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>configuration</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>recording_path</th>\n",
       "      <th>event_index</th>\n",
       "      <th>onset</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaaozv</td>\n",
       "      <td>s001_2013</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t001</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaaozv</td>\n",
       "      <td>s001_2013</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t001</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaaozv</td>\n",
       "      <td>s001_2013</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t001</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaaozv</td>\n",
       "      <td>s001_2013</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t001</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaaozv</td>\n",
       "      <td>s001_2013</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t001</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaajrj</td>\n",
       "      <td>s006_2012</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t005</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        set patient_id session_id configuration recording_id  \\\n",
       "0     train   aaaaaozv  s001_2013     01_tcp_ar         t001   \n",
       "1     train   aaaaaozv  s001_2013     01_tcp_ar         t001   \n",
       "2     train   aaaaaozv  s001_2013     01_tcp_ar         t001   \n",
       "3     train   aaaaaozv  s001_2013     01_tcp_ar         t001   \n",
       "4     train   aaaaaozv  s001_2013     01_tcp_ar         t001   \n",
       "...     ...        ...        ...           ...          ...   \n",
       "1521  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "1522  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "1523  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "1524  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "1525  train   aaaaajrj  s006_2012     01_tcp_ar         t005   \n",
       "\n",
       "                                         recording_path  event_index  onset  \\\n",
       "0     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0    0.0   \n",
       "1     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   20.0   \n",
       "2     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   40.0   \n",
       "3     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   60.0   \n",
       "4     /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0   80.0   \n",
       "...                                                 ...          ...    ...   \n",
       "1521  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  180.0   \n",
       "1522  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  200.0   \n",
       "1523  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  220.0   \n",
       "1524  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  240.0   \n",
       "1525  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  260.0   \n",
       "\n",
       "       stop label  \n",
       "0      30.0  bckg  \n",
       "1      50.0  bckg  \n",
       "2      70.0  bckg  \n",
       "3      90.0  bckg  \n",
       "4     110.0  bckg  \n",
       "...     ...   ...  \n",
       "1521  210.0  bckg  \n",
       "1522  230.0  bckg  \n",
       "1523  250.0  bckg  \n",
       "1524  270.0  bckg  \n",
       "1525  290.0  bckg  \n",
       "\n",
       "[1526 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_windows(tuh_eeg_seizure_corpus_path: str, window_length: int, overlap: int, configurations: list):\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"event_index\", \"onset\", \"stop\", \"label\"]\n",
    "    data = []\n",
    "    \n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".edf\"):\n",
    "                continue\n",
    "            \n",
    "            rel_path = os.path.relpath(root, edf_path)\n",
    "            parts = rel_path.split(\"/\")\n",
    "            \n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "        \n",
    "            set_name, patient_id, session_id, configuration = parts\n",
    "            \n",
    "            if configuration not in CONFIGURATIONS:\n",
    "                continue\n",
    "        \n",
    "            recording_path = os.path.join(root, file)\n",
    "            recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "            annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "            \n",
    "            if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                continue\n",
    "            \n",
    "            events = extract_events_from_annotations(annotation_path)\n",
    "            \n",
    "            for i, event in enumerate(events):\n",
    "                start_time = event[\"onset\"]\n",
    "                stop_time = event[\"onset\"] + event[\"duration\"]\n",
    "\n",
    "                if stop_time - start_time < WINDOW_LENGTH:\n",
    "                    continue\n",
    "\n",
    "                while start_time + WINDOW_LENGTH < stop_time:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"event_index\": i,\n",
    "                        \"onset\": start_time,\n",
    "                        \"stop\": start_time + WINDOW_LENGTH,\n",
    "                        \"label\": event[\"label\"],\n",
    "                    })\n",
    "                    \n",
    "                    start_time += WINDOW_LENGTH - OVERLAP\n",
    "\n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "windows = load_windows(RAW_PATH, WINDOW_LENGTH, OVERLAP, CONFIGURATIONS)\n",
    "windows\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba1d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce4e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "402d06b9b7f446ba",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e6c0c0edcb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "\n",
    "for i, event in data.iterrows():\n",
    "    patient_id = event[\"patient_id\"]\n",
    "    onset = event[\"onset\"]\n",
    "    duration = event[\"duration\"]\n",
    "    label = event[\"label\"]\n",
    "\n",
    "    num_windows = int(duration / WINDOW_LENGTH)\n",
    "\n",
    "    if num_windows == 0:\n",
    "        continue\n",
    "        \n",
    "    for i in range(num_windows):\n",
    "        windows.append({\n",
    "            \"patient_id\": patient_id,\n",
    "            \"onset\": onset + i * WINDOW_LENGTH,\n",
    "            \"duration\": WINDOW_LENGTH,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "windows = pd.DataFrame(windows)\n",
    "x = np.array(windows[\"duration\"])\n",
    "y = np.array(windows[\"label\"])\n",
    "groups = np.array(windows[\"patient_id\"])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "splits = list(cv.split(x, y, groups))\n",
    "test_fold_idx = np.random.choice(len(splits))\n",
    "\n",
    "train_idx, test_idx = splits[test_fold_idx]\n",
    "\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_test, y_test = x[test_idx], y[test_idx]\n",
    "\n",
    "# Get the number of positive/negative samples in both train and test and their ratio\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_ratio = counts[1] / counts[0]\n",
    "print(f\"Train - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Train ratio: {train_ratio}\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_ratio = counts[1] / counts[0]\n",
    "print(f\"Test - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Test ratio: {test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    mean = np.mean(coeffs)\n",
    "    median = np.median(coeffs)\n",
    "    std = np.std(coeffs)\n",
    "    variance = np.var(coeffs)\n",
    "    skew = sp.stats.skew(coeffs)\n",
    "    kurtosis = sp.stats.kurtosis(coeffs)\n",
    "    rms = np.sqrt(np.mean(coeffs ** 2))\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"variance\": variance,\n",
    "        \"std\": std,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "        \"rms\": rms\n",
    "    }\n",
    "    \n",
    "def extract_wavelet_features(channel_data: np.ndarray ) -> dict[str, float]:\n",
    "    a5, d5, d4, d3, d2, d1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    \n",
    "    wavelet_features = {f\"{coeff}_{stat}\": value \n",
    "                        for coeff, data in zip([\"a5\", \"d5\", \"d4\", \"d3\"], [a5, d5, d4, d3])\n",
    "                        for stat, value in calc_coeffs_features(data).items()}\n",
    "    \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37cbbd7296b02baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_band_power(channel_data, sfreq=SAMPLING_FREQ, n_fft=256) -> dict[str, float]:\n",
    "    frequency_bands = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 7),\n",
    "        \"alpha\": (7, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 50)\n",
    "    }\n",
    "\n",
    "    band_powers = {}\n",
    "\n",
    "    n_fft = min(n_fft, channel_data.shape[-1])\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(channel_data, sfreq=sfreq, n_fft=n_fft, fmin=0.5, fmax=50)\n",
    "\n",
    "    # Calculate power within each frequency band\n",
    "    for band, (fmin, fmax) in frequency_bands.items():\n",
    "        # Find indices of frequencies within the band\n",
    "        band_indices = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "\n",
    "        # Sum the power spectral density values within the band\n",
    "        band_power = np.sum(psds[band_indices])\n",
    "\n",
    "        band_powers[band] = band_power\n",
    "\n",
    "    return band_powers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2e9161530113c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_power_ratios(band_powers : dict[str, float]) -> dict[str, float]:\n",
    "    alpha_beta_ratio = band_powers[\"alpha\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_beta_ratio = band_powers[\"theta\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_alpha_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / (band_powers[\"beta\"] + band_powers[\"alpha\"]) if (band_powers[\"beta\"] + band_powers[\"alpha\"]) != 0 else np.nan\n",
    "    alpha_theta_ratio = band_powers[\"alpha\"] / band_powers[\"theta\"] if band_powers[\"theta\"] != 0 else np.nan\n",
    "    theta_alpha_ratio = band_powers[\"theta\"] / band_powers[\"alpha\"] if band_powers[\"alpha\"] != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        \"alpha_beta_ratio\": alpha_beta_ratio,\n",
    "        \"theta_beta_ratio\": theta_beta_ratio,\n",
    "        \"theta_alpha_beta_ratio\": theta_alpha_beta_ratio,\n",
    "        \"theta_alpha_beta_alpha_ratio\": theta_alpha_beta_alpha_ratio,\n",
    "        \"alpha_theta_ratio\": alpha_theta_ratio,\n",
    "        \"theta_alpha_ratio\": theta_alpha_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55a304d0cefaf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_band_powers(band_powers):\n",
    "    avg_band_powers = {}\n",
    "    for band in band_powers[0].keys():\n",
    "        avg_band_powers[band] = np.mean([bp[band] for bp in band_powers])\n",
    "        \n",
    "    return avg_band_powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb734f78e39421c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_asymmetry(band_powers):\n",
    "    left_power = 0\n",
    "    right_power = 0\n",
    "    \n",
    "    for i, channel in enumerate(CHANNELS):\n",
    "        if channel in LEFT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                left_power += power\n",
    "        elif channel in RIGHT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                right_power += power\n",
    "            \n",
    "    left_power = np.log(left_power) if left_power != 0 else 0\n",
    "    right_power = np.log(right_power) if right_power != 0 else 0\n",
    "    \n",
    "    asymmetry = left_power - right_power\n",
    "    return asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e45a45454716d",
   "metadata": {},
   "source": [
    "\n",
    "### pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8cfbf75e5c37dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_powerline_noise(raw):\n",
    "    powerline_noises = [50, 60]\n",
    "\n",
    "    for freq in powerline_noises:\n",
    "        raw.notch_filter(freqs=freq)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a4116df678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patient_id):\n",
    "    corrupted = []\n",
    "    windows = []\n",
    "    \n",
    "    # output directory\n",
    "    #seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"seizure\")\n",
    "    #non_seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"non_seizure\")\n",
    "    #os.makedirs(seizure_output_dir, exist_ok=True)\n",
    "    #os.makedirs(non_seizure_output_dir, exist_ok=True)\n",
    "    \n",
    "    patient_events = data[data[\"patient_id\"] == patient_id]\n",
    "    recordings = patient_events.groupby(\"recording_path\")\n",
    "    \n",
    "    for recording_path, events in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        \n",
    "        # sometimes meas date is corrupted/missing\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        events_onsets = events[\"onset\"].values\n",
    "        events_durations = events[\"duration\"].values\n",
    "        events_labels = events[\"label\"].values\n",
    "        \n",
    "        # create annotations\n",
    "        annotations = mne.Annotations(onset=events_onsets, duration=events_durations, description=events_labels)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for _, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            duration = event[\"duration\"]\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            min_windows = int(duration / WINDOW_LENGTH)\n",
    "            \n",
    "            if min_windows == 0:\n",
    "                continue\n",
    "                \n",
    "            if onset + duration > raw.times[-1]:\n",
    "                if onset + duration - 1/raw.info[\"sfreq\"] == raw.times[-1]:\n",
    "                    raw_event = raw.copy().crop(onset, raw.times[-1], include_tmax=True)\n",
    "                else:\n",
    "                    print(\"Corrupted annotation\", patient_id, event[\"session_id\"], event[\"recording_id\"])\n",
    "                    corrupted.append((patient_id, event[\"session_id\"], event[\"recording_id\"]))\n",
    "                    continue\n",
    "            else:\n",
    "                raw_event = raw.copy().crop(onset, onset + duration, include_tmax=False)\n",
    "                \n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH, overlap=OVERLAP, preload=True)\n",
    "            \n",
    "            # resample to desired sampling frequency\n",
    "            raw_event.resample(SAMPLING_FREQ)\n",
    "        \n",
    "            # apply 4th order butterworth filter\n",
    "            iir_params = dict(order=4, ftype='butter')\n",
    "            raw_event.filter(0.5, 50, method='iir', iir_params=iir_params)\n",
    "        \n",
    "            # remove powerline noise\n",
    "            raw_event = remove_powerline_noise(raw_event)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                channels = epochs.info[\"ch_names\"]\n",
    "                \n",
    "                epoch_features = {}\n",
    "                band_powers = []\n",
    "                \n",
    "                for i, channel in enumerate(channels):\n",
    "                    channel_data = epoch[i]\n",
    "                    \n",
    "                    # normalize channel data using min-max scaling\n",
    "                    channel_data = (channel_data - np.min(channel_data)) / (np.max(channel_data) - np.min(channel_data))\n",
    "                    \n",
    "                    wavelet_features = extract_wavelet_features(channel_data)\n",
    "                    band_power = extract_band_power(channel_data)\n",
    "                    \n",
    "                    for key, value in wavelet_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                    \n",
    "                    band_powers.append(band_power)\n",
    "                \n",
    "                avg_band_powers = calc_avg_band_powers(band_powers)\n",
    "                power_ratios = calc_power_ratios(avg_band_powers)\n",
    "                \n",
    "                asymmetry = calc_asymmetry(band_powers) \n",
    "                \n",
    "                epoch_features[\"asymmetry\"] = asymmetry\n",
    "                epoch_features[\"label\"] = label\n",
    "                epoch_features[\"patient_id\"] = patient_id\n",
    "                epoch_features = {**epoch_features, **avg_band_powers, **power_ratios}\n",
    "                windows.append(epoch_features)\n",
    "                \n",
    "            #output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "            #file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_epo.fif\"\n",
    "            #epochs.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return pd.DataFrame(windows), corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "853abfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_recordings(patient: pd.DataFrame):\n",
    "    corrupted = []\n",
    "    windows = []\n",
    "\n",
    "    recordings = patient.groupby(\"recording_path\")\n",
    "    \n",
    "    for recording_path, events in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        \n",
    "        # sometimes meas date is corrupted/missing\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        events_onsets = events[\"onset\"].values\n",
    "        events_stops = events[\"stop\"].values\n",
    "        events_durations = events_stops - events_onsets\n",
    "        events_labels = events[\"label\"].values\n",
    "        \n",
    "        # create annotations\n",
    "        annotations = mne.Annotations(onset=events_onsets, duration=events_durations, description=events_labels)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for _, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            stop = event[\"stop\"]\n",
    "            duration = stop - onset\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            if onset + duration > raw.times[-1]:\n",
    "                if onset + duration - 1/raw.info[\"sfreq\"] == raw.times[-1]:\n",
    "                    raw_event = raw.copy().crop(onset, raw.times[-1], include_tmax=True)\n",
    "                else:\n",
    "                    print(\"Corrupted annotation\", patient_id, event[\"session_id\"], event[\"recording_id\"])\n",
    "                    corrupted.append((patient_id, event[\"session_id\"], event[\"recording_id\"]))\n",
    "                    continue\n",
    "            else:\n",
    "                raw_event = raw.copy().crop(onset, onset + duration, include_tmax=False)\n",
    "                \n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH, overlap=OVERLAP, preload=True)\n",
    "            \n",
    "            # resample to desired sampling frequency\n",
    "            raw_event.resample(SAMPLING_FREQ)\n",
    "        \n",
    "            # apply 4th order butterworth filter\n",
    "            iir_params = dict(order=4, ftype='butter')\n",
    "            raw_event.filter(0.5, 50, method='iir', iir_params=iir_params)\n",
    "        \n",
    "            # remove powerline noise\n",
    "            raw_event = remove_powerline_noise(raw_event)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                channels = epochs.info[\"ch_names\"]\n",
    "                \n",
    "                epoch_features = {}\n",
    "                band_powers = []\n",
    "                \n",
    "                for i, channel in enumerate(channels):\n",
    "                    channel_data = epoch[i]\n",
    "                    \n",
    "                    # normalize channel data using min-max scaling\n",
    "                    channel_data = (channel_data - np.min(channel_data)) / (np.max(channel_data) - np.min(channel_data))\n",
    "                    \n",
    "                    wavelet_features = extract_wavelet_features(channel_data)\n",
    "                    band_power = extract_band_power(channel_data)\n",
    "                    \n",
    "                    for key, value in wavelet_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                    \n",
    "                    band_powers.append(band_power)\n",
    "                \n",
    "                avg_band_powers = calc_avg_band_powers(band_powers)\n",
    "                power_ratios = calc_power_ratios(avg_band_powers)\n",
    "                \n",
    "                asymmetry = calc_asymmetry(band_powers) \n",
    "                \n",
    "                epoch_features[\"asymmetry\"] = asymmetry\n",
    "                epoch_features[\"label\"] = label\n",
    "                epoch_features[\"patient_id\"] = patient_id\n",
    "                epoch_features = {**epoch_features, **avg_band_powers, **power_ratios}\n",
    "                windows.append(epoch_features)\n",
    "                \n",
    "            #output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "            #file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_epo.fif\"\n",
    "            #epochs.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return pd.DataFrame(windows), corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aaaaajrj\n",
      "Processing aaaaamoq\n",
      "Processing aaaaaozv\n"
     ]
    }
   ],
   "source": [
    "# group patient windows by recording path, aggregate onset to min and stop to max\n",
    "patient_recordings = windows.groupby([\"patient_id\", \"session_id\", \"recording_id\", \"recording_path\", \"event_index\"]).agg({\"onset\": \"min\", \"stop\": \"max\", \"label\": \"first\"}).reset_index()\n",
    "patient_ids = patient_recordings[\"patient_id\"].unique()\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "\n",
    "    p = patient_recordings[patient_recordings[\"patient_id\"] == patient_id]\n",
    "\n",
    "    print(\"Processing\", patient_id)\n",
    "\n",
    "    features, corrupted = preprocess_recordings(p)\n",
    "\n",
    "    w = windows[windows[\"patient_id\"] == patient_id]\n",
    "    \n",
    "    if features.shape[0] != w.shape[0]:\n",
    "        print(\"Mismatch\", features.shape[0], w.shape[0])\n",
    "        \n",
    "    if len(corrupted) > 0:\n",
    "        print(\"Corrupted\", corrupted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb849059b064f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64d728a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[windows[\"patient_id\"] == patient_ids[0]].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e78544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
