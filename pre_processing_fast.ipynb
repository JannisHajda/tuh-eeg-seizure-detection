{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 10\n",
    "CONFIGURATIONS = []\n",
    "CHANNELS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6fac45f4b713",
   "metadata": {},
   "source": [
    "#### extract events from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start_time = float(parts[1])\n",
    "            stop_time = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"onset\": start_time,\n",
    "                \"duration\": stop_time - start_time\n",
    "            })\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40cd685fe2e87a",
   "metadata": {},
   "source": [
    "#### load the TUH EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c5955aa64b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tuh_eeg():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"label\", \"onset\", \"duration\"]\n",
    "    data = []\n",
    "    \n",
    "    # get all edf files in RAW/edf\n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\"):\n",
    "                rel_path = os.path.relpath(root, edf_path)\n",
    "                parts = rel_path.split(\"/\")\n",
    "                \n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "                    \n",
    "                set_name, patient_id, session_id, configuration = parts\n",
    "                \n",
    "                recording_path = os.path.join(root, file)\n",
    "                recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "                annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "                \n",
    "                if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                    continue\n",
    "                \n",
    "                events = extract_events_from_annotations(annotation_path)\n",
    "                for event in events:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"label\": event[\"label\"],\n",
    "                        \"onset\": event[\"onset\"],\n",
    "                        \"duration\": event[\"duration\"]\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "data = load_tuh_eeg()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e45a45454716d",
   "metadata": {},
   "source": [
    "\n",
    "### pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a4116df678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patient):\n",
    "    corrupted = []\n",
    "    \n",
    "    # output directory\n",
    "    seizure_output_dir = os.path.join(OUTPUT_PATH, patient, \"seizure\")\n",
    "    non_seizure_output_dir = os.path.join(OUTPUT_PATH, patient, \"non_seizure\")\n",
    "    os.makedirs(seizure_output_dir, exist_ok=True)\n",
    "    os.makedirs(non_seizure_output_dir, exist_ok=True)\n",
    "    \n",
    "    recordings = data[data[\"patient_id\"] == patient][\"recording_path\"].unique()\n",
    "    \n",
    "    for recording in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording, preload=True)\n",
    "        \n",
    "        # sometimes meas date breaks code\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        # pre-processing to remove noise\n",
    "        raw.resample(SAMPLING_FREQ)\n",
    "    \n",
    "        events = data[data[\"recording_path\"] == recording]\n",
    "        \n",
    "        onset = events[\"onset\"].values\n",
    "        duration = events[\"duration\"].values\n",
    "        label = events[\"label\"].values\n",
    "        \n",
    "        annotations = mne.Annotations(onset=onset, duration=duration, description=label)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for _, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            duration = event[\"duration\"]\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            num_windows = int(duration / WINDOW_LENGTH)\n",
    "            \n",
    "            if num_windows == 0:\n",
    "                continue\n",
    "                \n",
    "            windows = [{\"start\": onset + i * WINDOW_LENGTH, \"stop\": onset + (i + 1) * WINDOW_LENGTH} for i in range(num_windows)]\n",
    "            window_df = pd.DataFrame(windows)\n",
    "            \n",
    "            for i, window in window_df.iterrows():\n",
    "                start = window[\"start\"]\n",
    "                stop = window[\"stop\"]\n",
    "                \n",
    "                output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "                file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_raw.fif\"\n",
    "     \n",
    "                \n",
    "                if stop > raw.times[-1]:\n",
    "                    if stop - 1/SAMPLING_FREQ == raw.times[-1]:\n",
    "                        stop = raw.times[-1]\n",
    "                        raw_window = raw.copy().crop(start, stop, include_tmax=True)\n",
    "                    else:\n",
    "                        print(\"Corrupted annotation\", file_name)\n",
    "                        corrupted.append(file_name)\n",
    "                        continue\n",
    "                else:\n",
    "                    raw_window = raw.copy().crop(start, stop, include_tmax=False)\n",
    "    \n",
    "                raw_window.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "                raw_window.close()\n",
    "        \n",
    "        raw.close()\n",
    "        \n",
    "    return corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c4b68d79d2fc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data[\"patient_id\"].unique()\n",
    "patients = patients[200:]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for patient in patients:\n",
    "        futures.append(executor.submit(preprocess, patient=patient))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ea0a3940b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"patient_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c0aad83637b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da840aed5c47d075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
