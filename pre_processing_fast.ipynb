{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "RAW_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/home/nis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 30\n",
    "OVERLAP = 10 \n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc1c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_channels_to_hemispheres(channels: list):\n",
    "    left_hemisphere = []\n",
    "    right_hemisphere = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel_number = re.search(r'\\d+', channel)\n",
    "        if channel_number is None:\n",
    "            continue\n",
    "        \n",
    "        if int(channel_number.group()) % 2 == 0:\n",
    "            right_hemisphere.append(channel)\n",
    "        else:\n",
    "            left_hemisphere.append(channel)\n",
    "    \n",
    "    return left_hemisphere, right_hemisphere\n",
    "\n",
    "LEFT_HEMISPHERE, RIGHT_HEMISPHERE = split_channels_to_hemispheres(CHANNELS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start = float(parts[1])\n",
    "            stop = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"start\": start,\n",
    "                \"stop\": stop,\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13556c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>configuration</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>recording_path</th>\n",
       "      <th>event_index</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s007_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t002</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>3</td>\n",
       "      <td>176.0310</td>\n",
       "      <td>206.0310</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s007_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t002</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>3</td>\n",
       "      <td>196.0310</td>\n",
       "      <td>226.0310</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s007_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t002</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>4</td>\n",
       "      <td>256.0288</td>\n",
       "      <td>286.0288</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s007_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t002</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>4</td>\n",
       "      <td>276.0288</td>\n",
       "      <td>306.0288</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s007_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t002</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>4</td>\n",
       "      <td>296.0288</td>\n",
       "      <td>326.0288</td>\n",
       "      <td>seiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s002_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0000</td>\n",
       "      <td>210.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s002_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0000</td>\n",
       "      <td>230.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s002_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>220.0000</td>\n",
       "      <td>250.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s002_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>240.0000</td>\n",
       "      <td>270.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>train</td>\n",
       "      <td>aaaaates</td>\n",
       "      <td>s002_2015</td>\n",
       "      <td>01_tcp_ar</td>\n",
       "      <td>t008</td>\n",
       "      <td>/home/nis/Git/tuh-eeg-seizure-detection/data/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0000</td>\n",
       "      <td>290.0000</td>\n",
       "      <td>bckg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       set patient_id session_id configuration recording_id  \\\n",
       "0    train   aaaaates  s007_2015     01_tcp_ar         t002   \n",
       "1    train   aaaaates  s007_2015     01_tcp_ar         t002   \n",
       "2    train   aaaaates  s007_2015     01_tcp_ar         t002   \n",
       "3    train   aaaaates  s007_2015     01_tcp_ar         t002   \n",
       "4    train   aaaaates  s007_2015     01_tcp_ar         t002   \n",
       "..     ...        ...        ...           ...          ...   \n",
       "982  train   aaaaates  s002_2015     01_tcp_ar         t008   \n",
       "983  train   aaaaates  s002_2015     01_tcp_ar         t008   \n",
       "984  train   aaaaates  s002_2015     01_tcp_ar         t008   \n",
       "985  train   aaaaates  s002_2015     01_tcp_ar         t008   \n",
       "986  train   aaaaates  s002_2015     01_tcp_ar         t008   \n",
       "\n",
       "                                        recording_path  event_index     start  \\\n",
       "0    /home/nis/Git/tuh-eeg-seizure-detection/data/r...            3  176.0310   \n",
       "1    /home/nis/Git/tuh-eeg-seizure-detection/data/r...            3  196.0310   \n",
       "2    /home/nis/Git/tuh-eeg-seizure-detection/data/r...            4  256.0288   \n",
       "3    /home/nis/Git/tuh-eeg-seizure-detection/data/r...            4  276.0288   \n",
       "4    /home/nis/Git/tuh-eeg-seizure-detection/data/r...            4  296.0288   \n",
       "..                                                 ...          ...       ...   \n",
       "982  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  180.0000   \n",
       "983  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  200.0000   \n",
       "984  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  220.0000   \n",
       "985  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  240.0000   \n",
       "986  /home/nis/Git/tuh-eeg-seizure-detection/data/r...            0  260.0000   \n",
       "\n",
       "         stop label  \n",
       "0    206.0310  seiz  \n",
       "1    226.0310  seiz  \n",
       "2    286.0288  seiz  \n",
       "3    306.0288  seiz  \n",
       "4    326.0288  seiz  \n",
       "..        ...   ...  \n",
       "982  210.0000  bckg  \n",
       "983  230.0000  bckg  \n",
       "984  250.0000  bckg  \n",
       "985  270.0000  bckg  \n",
       "986  290.0000  bckg  \n",
       "\n",
       "[987 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_windows():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"event_index\", \"start\", \"stop\", \"label\"]\n",
    "    data = []\n",
    "    \n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    \n",
    "    for root, _, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".edf\"):\n",
    "                continue\n",
    "            \n",
    "            rel_path = os.path.relpath(root, edf_path)\n",
    "            parts = rel_path.split(\"/\")\n",
    "            \n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "        \n",
    "            set_name, patient_id, session_id, configuration = parts\n",
    "            \n",
    "            if configuration not in CONFIGURATIONS:\n",
    "                continue\n",
    "        \n",
    "            recording_path = os.path.join(root, file)\n",
    "            recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "            annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "            \n",
    "            if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                continue\n",
    "            \n",
    "            events = extract_events_from_annotations(annotation_path)\n",
    "            \n",
    "            for i, event in events.iterrows():\n",
    "                start, stop, label = event.loc[[\"start\", \"stop\", \"label\"]]\n",
    "                duration = stop - start\n",
    "\n",
    "                if duration < WINDOW_LENGTH:\n",
    "                    continue\n",
    "\n",
    "                while start + WINDOW_LENGTH < stop:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"event_index\": i,\n",
    "                        \"start\": start,\n",
    "                        \"stop\": start + WINDOW_LENGTH,\n",
    "                        \"label\": label,\n",
    "                    })\n",
    "                    \n",
    "                    start += WINDOW_LENGTH - OVERLAP\n",
    "\n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "windows = load_windows()\n",
    "windows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    mean = np.mean(coeffs)\n",
    "    median = np.median(coeffs)\n",
    "    std = np.std(coeffs)\n",
    "    variance = np.var(coeffs)\n",
    "    skew = sp.stats.skew(coeffs)\n",
    "    kurtosis = sp.stats.kurtosis(coeffs)\n",
    "    rms = np.sqrt(np.mean(coeffs ** 2))\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"variance\": variance,\n",
    "        \"std\": std,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "        \"rms\": rms\n",
    "    }\n",
    "    \n",
    "def extract_wavelet_features(channel_data: np.ndarray ) -> dict[str, float]:\n",
    "    a5, d5, d4, d3, d2, d1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    \n",
    "    wavelet_features = {f\"{coeff}_{stat}\": value \n",
    "                        for coeff, data in zip([\"a5\", \"d5\", \"d4\", \"d3\"], [a5, d5, d4, d3])\n",
    "                        for stat, value in calc_coeffs_features(data).items()}\n",
    "    \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cbbd7296b02baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_band_power(channel_data, sfreq=SAMPLING_FREQ, n_fft=256) -> dict[str, float]:\n",
    "    frequency_bands = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 7),\n",
    "        \"alpha\": (7, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 50)\n",
    "    }\n",
    "\n",
    "    band_powers = {}\n",
    "\n",
    "    n_fft = min(n_fft, channel_data.shape[-1])\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(channel_data, sfreq=sfreq, n_fft=n_fft, fmin=0.5, fmax=50)\n",
    "\n",
    "    # Calculate power within each frequency band\n",
    "    for band, (fmin, fmax) in frequency_bands.items():\n",
    "        # Find indices of frequencies within the band\n",
    "        band_indices = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "\n",
    "        # Sum the power spectral density values within the band\n",
    "        band_power = np.sum(psds[band_indices])\n",
    "\n",
    "        band_powers[band] = band_power\n",
    "\n",
    "    return band_powers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e9161530113c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_power_ratios(band_powers : dict[str, float]) -> dict[str, float]:\n",
    "    alpha_beta_ratio = band_powers[\"alpha\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_beta_ratio = band_powers[\"theta\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_alpha_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / (band_powers[\"beta\"] + band_powers[\"alpha\"]) if (band_powers[\"beta\"] + band_powers[\"alpha\"]) != 0 else np.nan\n",
    "    alpha_theta_ratio = band_powers[\"alpha\"] / band_powers[\"theta\"] if band_powers[\"theta\"] != 0 else np.nan\n",
    "    theta_alpha_ratio = band_powers[\"theta\"] / band_powers[\"alpha\"] if band_powers[\"alpha\"] != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        \"alpha_beta_ratio\": alpha_beta_ratio,\n",
    "        \"theta_beta_ratio\": theta_beta_ratio,\n",
    "        \"theta_alpha_beta_ratio\": theta_alpha_beta_ratio,\n",
    "        \"theta_alpha_beta_alpha_ratio\": theta_alpha_beta_alpha_ratio,\n",
    "        \"alpha_theta_ratio\": alpha_theta_ratio,\n",
    "        \"theta_alpha_ratio\": theta_alpha_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a304d0cefaf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_band_powers(band_powers):\n",
    "    avg_band_powers = {}\n",
    "    for band in band_powers[0].keys():\n",
    "        avg_band_powers[band] = np.mean([bp[band] for bp in band_powers])\n",
    "        \n",
    "    return avg_band_powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb734f78e39421c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_asymmetry(band_powers):\n",
    "    left_power = 0\n",
    "    right_power = 0\n",
    "    \n",
    "    for i, channel in enumerate(CHANNELS):\n",
    "        if channel in LEFT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                left_power += power\n",
    "        elif channel in RIGHT_HEMISPHERE:\n",
    "            powers = list(band_powers[i].values())\n",
    "            for power in powers:\n",
    "                right_power += power\n",
    "            \n",
    "    left_power = np.log(left_power) if left_power != 0 else 0\n",
    "    right_power = np.log(right_power) if right_power != 0 else 0\n",
    "    \n",
    "    asymmetry = left_power - right_power\n",
    "    return asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6baf8",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8cfbf75e5c37dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_powerline_noise(raw):\n",
    "    powerline_noises = [50, 60]\n",
    "\n",
    "    for freq in powerline_noises:\n",
    "        raw.notch_filter(freqs=freq)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269b9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterworth_filter(raw):\n",
    "    iir_params = dict(order=4, ftype='butter')\n",
    "    raw.filter(0.5, 50, method='iir', iir_params=iir_params)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2a1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dac3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_raw_event(raw, start, stop):\n",
    "    \"\"\"Crops the raw data based on the onset and duration, handling edge cases.\"\"\"\n",
    "    if stop > raw.times[-1]:\n",
    "        if stop - 1 / raw.info[\"sfreq\"] == raw.times[-1]:\n",
    "            return raw.copy().crop(start, raw.times[-1], include_tmax=True), True\n",
    "        else:\n",
    "            return None, False\n",
    "    else:\n",
    "        return raw.copy().crop(start, stop, include_tmax=False), True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1e8e8",
   "metadata": {},
   "source": [
    "### process windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "853abfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_windows(windows: pd.DataFrame):\n",
    "    corrupted = []\n",
    "    features = []\n",
    "\n",
    "    windows = windows.groupby([\"set\", \"patient_id\", \"session_id\", \"recording_id\", \"recording_path\", \"event_index\"]).agg({\n",
    "        \"start\": \"min\",\n",
    "        \"stop\": \"max\",\n",
    "        \"label\": \"first\"\n",
    "    }).reset_index()\n",
    "    \n",
    "    recordings = windows.groupby(\"recording_path\")\n",
    "    \n",
    "    for recording_path, events in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        for _, event in events.iterrows():\n",
    "            patient_id, session_id, recording_id, event_index, start, stop, label  = event.loc[[\"patient_id\", \"session_id\", \"recording_id\", \"event_index\", \"start\", \"stop\", \"label\"]]\n",
    "\n",
    "            raw_event, success = crop_raw_event(raw, start, stop)\n",
    "            if not success:\n",
    "                print(\"Corrupted annotation\", patient_id, session_id, recording_id)\n",
    "                corrupted.append((patient_id, session_id, recording_id))\n",
    "            \n",
    "            raw_event.resample(SAMPLING_FREQ)\n",
    "\n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH, overlap=OVERLAP, preload=True)\n",
    "        \n",
    "            raw_event = butterworth_filter(raw_event) \n",
    "            raw_event = remove_powerline_noise(raw_event)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                channels = epochs.info[\"ch_names\"]\n",
    "                \n",
    "                epoch_features = {}\n",
    "                band_powers = []\n",
    "                \n",
    "                for j, channel in enumerate(channels):\n",
    "                    channel_data = epoch[j]\n",
    "                    channel_data = min_max_normalization(channel_data)\n",
    "                    \n",
    "                    wavelet_features = extract_wavelet_features(channel_data)\n",
    "                    band_power = extract_band_power(channel_data)\n",
    "                    \n",
    "                    for key, value in wavelet_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                    \n",
    "                    band_powers.append(band_power)\n",
    "                \n",
    "                avg_band_powers = calc_avg_band_powers(band_powers)\n",
    "                power_ratios = calc_power_ratios(avg_band_powers)\n",
    "                \n",
    "                asymmetry = calc_asymmetry(band_powers) \n",
    "                \n",
    "                epoch_features.update({\n",
    "                    \"patient_id\": patient_id,\n",
    "                    \"session_id\": session_id,\n",
    "                    \"recording_id\": recording_id,\n",
    "                    \"recording_path\": recording_path,\n",
    "                    \"event_index\": event_index,\n",
    "                    \"asymmetry\": asymmetry,\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "                epoch_features = {**epoch_features, **avg_band_powers, **power_ratios}\n",
    "\n",
    "                features.append(epoch_features)\n",
    "                \n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return pd.DataFrame(features), corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, corrupted = process_windows(windows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
