{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 10\n",
    "CONFIGURATIONS = []\n",
    "CHANNELS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6fac45f4b713",
   "metadata": {},
   "source": [
    "#### extract events from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start_time = float(parts[1])\n",
    "            stop_time = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"onset\": start_time,\n",
    "                \"duration\": stop_time - start_time\n",
    "            })\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40cd685fe2e87a",
   "metadata": {},
   "source": [
    "#### load the TUH EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c5955aa64b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tuh_eeg():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"label\", \"onset\", \"duration\"]\n",
    "    data = []\n",
    "    \n",
    "    # get all edf files in RAW/edf\n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\"):\n",
    "                rel_path = os.path.relpath(root, edf_path)\n",
    "                parts = rel_path.split(\"/\")\n",
    "                \n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "                    \n",
    "                set_name, patient_id, session_id, configuration = parts\n",
    "                \n",
    "                recording_path = os.path.join(root, file)\n",
    "                recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "                annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "                \n",
    "                if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                    continue\n",
    "                \n",
    "                events = extract_events_from_annotations(annotation_path)\n",
    "                for event in events:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"label\": event[\"label\"],\n",
    "                        \"onset\": event[\"onset\"],\n",
    "                        \"duration\": event[\"duration\"]\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "data = load_tuh_eeg()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    mean = np.mean(coeffs)\n",
    "    median = np.median(coeffs)\n",
    "    std = np.std(coeffs)\n",
    "    skew = sp.stats.skew(coeffs)\n",
    "    kurtosis = sp.stats.kurtosis(coeffs)\n",
    "    rms = np.sqrt(np.mean(coeffs**2))\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"std\": std,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "        \"rms\": rms\n",
    "    } \n",
    "    \n",
    "def extract_wavelet_features(channel_data):\n",
    "    cA5, cD5, cD4, cD3, cD2, cD1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    \n",
    "    d3_features = calc_coeffs_features(cD3)\n",
    "    d4_features = calc_coeffs_features(cD4)\n",
    "    d5_features = calc_coeffs_features(cD5)\n",
    "    a5_features = calc_coeffs_features(cA5)\n",
    "    \n",
    "    # rename keys to include the level\n",
    "    d3_features = {f\"d3_{k}\": v for k, v in d3_features.items()}\n",
    "    d4_features = {f\"d4_{k}\": v for k, v in d4_features.items()}\n",
    "    d5_features = {f\"d5_{k}\": v for k, v in d5_features.items()}\n",
    "    a5_features = {f\"a5_{k}\": v for k, v in a5_features.items()}\n",
    "    \n",
    "    features = {}\n",
    "    features.update(a5_features)\n",
    "    features.update(d3_features)\n",
    "    features.update(d4_features)\n",
    "    features.update(d5_features) \n",
    "     \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e45a45454716d",
   "metadata": {},
   "source": [
    "\n",
    "### pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a4116df678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patient_id):\n",
    "    corrupted = []\n",
    "    \n",
    "    # output directory\n",
    "    seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"seizure\")\n",
    "    non_seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"non_seizure\")\n",
    "    os.makedirs(seizure_output_dir, exist_ok=True)\n",
    "    os.makedirs(non_seizure_output_dir, exist_ok=True)\n",
    "    \n",
    "    recordings = data[data[\"patient_id\"] == patient_id][\"recording_path\"].unique()\n",
    "    \n",
    "    for recording in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording, preload=True).pick_channels(CHANNELS)\n",
    "        \n",
    "        # sometimes meas date breaks code\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        # pre-processing to remove noise\n",
    "        raw.resample(SAMPLING_FREQ)\n",
    "    \n",
    "        events = data[data[\"recording_path\"] == recording]\n",
    "        \n",
    "        onset = events[\"onset\"].values\n",
    "        duration = events[\"duration\"].values\n",
    "        label = events[\"label\"].values\n",
    "        \n",
    "        annotations = mne.Annotations(onset=onset, duration=duration, description=label)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for i, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            duration = event[\"duration\"]\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            num_windows = int(duration / WINDOW_LENGTH)\n",
    "            \n",
    "            if num_windows == 0:\n",
    "                continue\n",
    "                \n",
    "            if onset + duration > raw.times[-1]:\n",
    "                if onset + duration - 1/SAMPLING_FREQ == raw.times[-1]:\n",
    "                    raw_event = raw.copy().crop(onset, raw.times[-1], include_tmax=True)\n",
    "                else:\n",
    "                    print(\"Corrupted annotation\", patient_id, event[\"session_id\"], event[\"recording_id\"])\n",
    "                    corrupted.append((patient_id, event[\"session_id\"], event[\"recording_id\"]))\n",
    "                    continue\n",
    "            else:\n",
    "                raw_event = raw.copy().crop(onset, onset + duration, include_tmax=False)\n",
    "                \n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                for channel in epoch:\n",
    "                    features = extract_wavelet_features(channel)\n",
    "                    print(features)\n",
    "                \n",
    "            output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "            file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_epo.fif\"\n",
    "            epochs.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c4b68d79d2fc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data[\"patient_id\"].unique()\n",
    "patients = patients[200:210]\n",
    "patient = patients[0]\n",
    "preprocess(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ea0a3940b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"patient_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e52c877762f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c0aad83637b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da840aed5c47d075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
