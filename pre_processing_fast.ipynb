{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 10\n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6fac45f4b713",
   "metadata": {},
   "source": [
    "#### extract events from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start_time = float(parts[1])\n",
    "            stop_time = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"onset\": start_time,\n",
    "                \"duration\": stop_time - start_time\n",
    "            })\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40cd685fe2e87a",
   "metadata": {},
   "source": [
    "#### load the TUH EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c5955aa64b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tuh_eeg():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"label\", \"onset\", \"duration\"]\n",
    "    data = []\n",
    "    \n",
    "    # get all edf files in RAW/edf\n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\"):\n",
    "                rel_path = os.path.relpath(root, edf_path)\n",
    "                parts = rel_path.split(\"/\")\n",
    "                \n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "                    \n",
    "                set_name, patient_id, session_id, configuration = parts\n",
    "                \n",
    "                if configuration not in CONFIGURATIONS:\n",
    "                    continue\n",
    "                \n",
    "                recording_path = os.path.join(root, file)\n",
    "                recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "                annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "                \n",
    "                if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                    continue\n",
    "                \n",
    "                events = extract_events_from_annotations(annotation_path)\n",
    "                for event in events:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"label\": event[\"label\"],\n",
    "                        \"onset\": event[\"onset\"],\n",
    "                        \"duration\": event[\"duration\"]\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "data = load_tuh_eeg()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d06b9b7f446ba",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e6c0c0edcb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "\n",
    "for i, event in data.iterrows():\n",
    "    patient_id = event[\"patient_id\"]\n",
    "    onset = event[\"onset\"]\n",
    "    duration = event[\"duration\"]\n",
    "    label = event[\"label\"]\n",
    "\n",
    "    num_windows = int(duration / WINDOW_LENGTH)\n",
    "\n",
    "    if num_windows == 0:\n",
    "        continue\n",
    "        \n",
    "    for i in range(num_windows):\n",
    "        windows.append({\n",
    "            \"patient_id\": patient_id,\n",
    "            \"onset\": onset + i * WINDOW_LENGTH,\n",
    "            \"duration\": WINDOW_LENGTH,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "windows = pd.DataFrame(windows)\n",
    "x = np.array(windows[\"duration\"])\n",
    "y = np.array(windows[\"label\"])\n",
    "groups = np.array(windows[\"patient_id\"])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "splits = list(cv.split(x, y, groups))\n",
    "test_fold_idx = np.random.choice(len(splits))\n",
    "\n",
    "train_idx, test_idx = splits[test_fold_idx]\n",
    "\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_test, y_test = x[test_idx], y[test_idx]\n",
    "\n",
    "# Get the number of positive/negative samples in both train and test and their ratio\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_ratio = counts[1] / counts[0]\n",
    "print(f\"Train - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Train ratio: {train_ratio}\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_ratio = counts[1] / counts[0]\n",
    "print(f\"Test - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Test ratio: {test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    mean = np.mean(coeffs)\n",
    "    median = np.median(coeffs)\n",
    "    std = np.std(coeffs)\n",
    "    skew = sp.stats.skew(coeffs)\n",
    "    kurtosis = sp.stats.kurtosis(coeffs)\n",
    "    rms = np.sqrt(np.mean(coeffs**2))\n",
    "    \n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"median\": median,\n",
    "        \"std\": std,\n",
    "        \"skew\": skew,\n",
    "        \"kurtosis\": kurtosis,\n",
    "        \"rms\": rms\n",
    "    } \n",
    "    \n",
    "def extract_wavelet_features(channel_data):\n",
    "    cA5, cD5, cD4, cD3, cD2, cD1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    \n",
    "    d3_features = calc_coeffs_features(cD3)\n",
    "    d4_features = calc_coeffs_features(cD4)\n",
    "    d5_features = calc_coeffs_features(cD5)\n",
    "    a5_features = calc_coeffs_features(cA5)\n",
    "    \n",
    "    # rename keys to include the level\n",
    "    d3_features = {f\"d3_{k}\": v for k, v in d3_features.items()}\n",
    "    d4_features = {f\"d4_{k}\": v for k, v in d4_features.items()}\n",
    "    d5_features = {f\"d5_{k}\": v for k, v in d5_features.items()}\n",
    "    a5_features = {f\"a5_{k}\": v for k, v in a5_features.items()}\n",
    "    \n",
    "    features = {}\n",
    "    features.update(a5_features)\n",
    "    features.update(d3_features)\n",
    "    features.update(d4_features)\n",
    "    features.update(d5_features) \n",
    "     \n",
    "    return features\n",
    "\n",
    "def extract_power_features(channel_data, sfreq=SAMPLING_FREQ, n_fft=256):\n",
    "    frequency_bands = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 7),\n",
    "        \"alpha\": (7, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 50)\n",
    "    }\n",
    "    \n",
    "    power_features = {}\n",
    "    band_powers = {}\n",
    "    \n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(channel_data, sfreq=sfreq, n_fft=n_fft, fmin=0.5, fmax=50)\n",
    "\n",
    "    # Calculate power within each frequency band\n",
    "    for band, (fmin, fmax) in frequency_bands.items():\n",
    "        # Find indices of frequencies within the band\n",
    "        band_indices = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "        # Sum the power spectral density values within the band\n",
    "        band_power = np.sum(psds[band_indices])\n",
    "        power_features[f'power_{band}'] = band_power\n",
    "        band_powers[band] = band_power  # Store the band power for ratio calculations\n",
    "\n",
    "    # Calculate power ratios\n",
    "    alpha_beta_ratio = band_powers['alpha'] / band_powers['beta'] if band_powers['beta'] != 0 else np.nan\n",
    "    theta_beta_ratio = band_powers['theta'] / band_powers['beta'] if band_powers['beta'] != 0 else np.nan\n",
    "    theta_alpha_beta_ratio = (band_powers['theta'] + band_powers['alpha']) / band_powers['beta'] if band_powers['beta'] != 0 else np.nan\n",
    "    theta_alpha_beta_alpha_ratio = (band_powers['theta'] + band_powers['alpha']) / (band_powers['beta'] + band_powers['alpha']) if (band_powers['beta'] + band_powers['alpha']) != 0 else np.nan\n",
    "    alpha_theta_ratio = band_powers['alpha'] / band_powers['theta'] if band_powers['theta'] != 0 else np.nan\n",
    "    theta_alpha_ratio = band_powers['theta'] / band_powers['alpha'] if band_powers['alpha'] != 0 else np.nan\n",
    "\n",
    "    power_features['alpha_beta_ratio'] = alpha_beta_ratio\n",
    "    power_features['theta_beta_ratio'] = theta_beta_ratio\n",
    "    power_features['(theta+alpha)_beta_ratio'] = theta_alpha_beta_ratio\n",
    "    power_features['(theta+alpha)/(beta+alpha)_ratio'] = theta_alpha_beta_alpha_ratio\n",
    "    power_features['alpha_theta_ratio'] = alpha_theta_ratio\n",
    "    power_features['theta_alpha_ratio'] = theta_alpha_ratio\n",
    "    \n",
    "    return power_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9161530113c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6e45a45454716d",
   "metadata": {},
   "source": [
    "\n",
    "### pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a4116df678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patient_id):\n",
    "    corrupted = []\n",
    "    windows = []\n",
    "    \n",
    "    # output directory\n",
    "    seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"seizure\")\n",
    "    non_seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"non_seizure\")\n",
    "    os.makedirs(seizure_output_dir, exist_ok=True)\n",
    "    os.makedirs(non_seizure_output_dir, exist_ok=True)\n",
    "    \n",
    "    recordings = data[data[\"patient_id\"] == patient_id][\"recording_path\"].unique()\n",
    "    \n",
    "    for recording in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording, preload=True).pick_channels(CHANNELS)\n",
    "        \n",
    "        # sometimes meas date breaks code\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        # pre-processing to remove noise\n",
    "        raw.resample(SAMPLING_FREQ)\n",
    "    \n",
    "        events = data[data[\"recording_path\"] == recording]\n",
    "        \n",
    "        onset = events[\"onset\"].values\n",
    "        duration = events[\"duration\"].values\n",
    "        label = events[\"label\"].values\n",
    "        \n",
    "        annotations = mne.Annotations(onset=onset, duration=duration, description=label)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for i, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            duration = event[\"duration\"]\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            num_windows = int(duration / WINDOW_LENGTH)\n",
    "            \n",
    "            if num_windows == 0:\n",
    "                continue\n",
    "                \n",
    "            if onset + duration > raw.times[-1]:\n",
    "                if onset + duration - 1/SAMPLING_FREQ == raw.times[-1]:\n",
    "                    raw_event = raw.copy().crop(onset, raw.times[-1], include_tmax=True)\n",
    "                else:\n",
    "                    print(\"Corrupted annotation\", patient_id, event[\"session_id\"], event[\"recording_id\"])\n",
    "                    corrupted.append((patient_id, event[\"session_id\"], event[\"recording_id\"]))\n",
    "                    continue\n",
    "            else:\n",
    "                raw_event = raw.copy().crop(onset, onset + duration, include_tmax=False)\n",
    "                \n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                epoch_features = {}\n",
    "                for i, channel in enumerate(raw.info[\"ch_names\"]):\n",
    "                    wavelet_features = extract_wavelet_features(epoch[i])\n",
    "                    power_features = extract_power_features(epoch[i])\n",
    "                    \n",
    "                    for key, value in wavelet_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                    for key, value in power_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                \n",
    "                epoch_features[\"label\"] = label\n",
    "                epoch_features[\"patient_id\"] = patient_id\n",
    "                windows.append(epoch_features)\n",
    "               \n",
    "            #output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "            #file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_epo.fif\"\n",
    "            #epochs.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return pd.DataFrame(windows), corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c4b68d79d2fc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data[\"patient_id\"].unique()\n",
    "patients = patients[200:210]\n",
    "extracted_features = []\n",
    "corrupted = []\n",
    "for patient in patients:\n",
    "    features, corrupted = preprocess(patient)\n",
    "    extracted_features.append(features)\n",
    "    corrupted.extend(corrupted)\n",
    "    \n",
    "extracted_features = pd.concat(extracted_features)\n",
    "extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ea0a3940b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb849059b064f23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
