{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599a272864cdf9e2",
   "metadata": {},
   "source": [
    "# Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad884de149379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pywt\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a548a065ad8e1",
   "metadata": {},
   "source": [
    "### configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa827c8a95fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "\n",
    "RAW_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/raw'\n",
    "OUTPUT_PATH = '/Users/jannis/Git/tuh-eeg-seizure-detection/data/processed_fast'\n",
    "\n",
    "SAMPLING_FREQ = 250\n",
    "WINDOW_LENGTH = 30\n",
    "OVERLAP = 10 \n",
    "CONFIGURATIONS = [\"01_tcp_ar\"]\n",
    "CHANNELS = [\"EEG FP1-REF\", \"EEG FP2-REF\", \"EEG F7-REF\", \"EEG F3-REF\", \"EEG F4-REF\", \"EEG F8-REF\", \"EEG T3-REF\", \"EEG C3-REF\", \"EEG C4-REF\", \"EEG T4-REF\", \"EEG T5-REF\", \"EEG P3-REF\", \"EEG P4-REF\", \"EEG T6-REF\", \"EEG O1-REF\", \"EEG O2-REF\", \"EEG CZ-REF\", \"EEG A1-REF\", \"EEG A2-REF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2863b3b35701",
   "metadata": {},
   "source": [
    "### load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb6fac45f4b713",
   "metadata": {},
   "source": [
    "#### extract events from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bb6bc05c75d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events_from_annotations(annotation_file):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        annotations = f.readlines()\n",
    "        events = annotations[6:] \n",
    "        \n",
    "        data = []\n",
    "        for event in events:\n",
    "            parts = event.split(\",\")\n",
    "            \n",
    "            start_time = float(parts[1])\n",
    "            stop_time = float(parts[2])\n",
    "            label = parts[3]\n",
    "            \n",
    "            data.append({\n",
    "                \"label\": label,\n",
    "                \"onset\": start_time,\n",
    "                \"duration\": stop_time - start_time\n",
    "            })\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40cd685fe2e87a",
   "metadata": {},
   "source": [
    "#### load the TUH EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c5955aa64b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tuh_eeg():\n",
    "    cols = [\"set\", \"patient_id\", \"session_id\", \"configuration\", \"recording_id\", \"recording_path\", \"label\", \"onset\", \"duration\"]\n",
    "    data = []\n",
    "    \n",
    "    # get all edf files in RAW/edf\n",
    "    edf_path = os.path.join(RAW_PATH, \"edf\")\n",
    "    for root, dirs, files in os.walk(edf_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".edf\"):\n",
    "                rel_path = os.path.relpath(root, edf_path)\n",
    "                parts = rel_path.split(\"/\")\n",
    "                \n",
    "                if len(parts) != 4:\n",
    "                    continue\n",
    "                    \n",
    "                set_name, patient_id, session_id, configuration = parts\n",
    "                \n",
    "                if configuration not in CONFIGURATIONS:\n",
    "                    continue\n",
    "                \n",
    "                recording_path = os.path.join(root, file)\n",
    "                recording_id = file.replace(\".edf\", \"\").split(\"_\")[-1]\n",
    "                annotation_path = recording_path.replace(\".edf\", \".csv_bi\")\n",
    "                \n",
    "                if not os.path.exists(recording_path) or not os.path.exists(annotation_path):\n",
    "                    continue\n",
    "                \n",
    "                events = extract_events_from_annotations(annotation_path)\n",
    "                for event in events:\n",
    "                    data.append({\n",
    "                        \"set\": set_name,\n",
    "                        \"patient_id\": patient_id,\n",
    "                        \"session_id\": session_id,\n",
    "                        \"configuration\": configuration,\n",
    "                        \"recording_id\": recording_id,\n",
    "                        \"recording_path\": recording_path,\n",
    "                        \"label\": event[\"label\"],\n",
    "                        \"onset\": event[\"onset\"],\n",
    "                        \"duration\": event[\"duration\"]\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(data, columns=cols)\n",
    "\n",
    "data = load_tuh_eeg()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d06b9b7f446ba",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e6c0c0edcb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "\n",
    "for i, event in data.iterrows():\n",
    "    patient_id = event[\"patient_id\"]\n",
    "    onset = event[\"onset\"]\n",
    "    duration = event[\"duration\"]\n",
    "    label = event[\"label\"]\n",
    "\n",
    "    num_windows = int(duration / WINDOW_LENGTH)\n",
    "\n",
    "    if num_windows == 0:\n",
    "        continue\n",
    "        \n",
    "    for i in range(num_windows):\n",
    "        windows.append({\n",
    "            \"patient_id\": patient_id,\n",
    "            \"onset\": onset + i * WINDOW_LENGTH,\n",
    "            \"duration\": WINDOW_LENGTH,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "windows = pd.DataFrame(windows)\n",
    "x = np.array(windows[\"duration\"])\n",
    "y = np.array(windows[\"label\"])\n",
    "groups = np.array(windows[\"patient_id\"])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "splits = list(cv.split(x, y, groups))\n",
    "test_fold_idx = np.random.choice(len(splits))\n",
    "\n",
    "train_idx, test_idx = splits[test_fold_idx]\n",
    "\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_test, y_test = x[test_idx], y[test_idx]\n",
    "\n",
    "# Get the number of positive/negative samples in both train and test and their ratio\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_ratio = counts[1] / counts[0]\n",
    "print(f\"Train - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Train ratio: {train_ratio}\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_ratio = counts[1] / counts[0]\n",
    "print(f\"Test - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Test ratio: {test_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37962864007a52",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34342c03673a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeffs_features(coeffs):\n",
    "    return {\n",
    "        \"mean\": np.mean(coeffs),\n",
    "        \"median\": np.median(coeffs),\n",
    "        \"std\": np.std(coeffs),\n",
    "        \"skew\": sp.stats.skew(coeffs),\n",
    "        \"kurtosis\": sp.stats.kurtosis(coeffs),\n",
    "        \"rms\": np.sqrt(np.mean(coeffs ** 2))\n",
    "    }\n",
    "    \n",
    "def extract_wavelet_features(channel_data: np.ndarray ) -> dict[str, float]:\n",
    "    a5, d5, d4, d3, d2, d1 = pywt.wavedec(channel_data, 'db4', level=5)\n",
    "    wavelet_features = {}\n",
    "    \n",
    "    for i, coeffs in zip([\"a5\", \"d5\", \"d4\", \"d3\"], [a5, d5, d4, d3]):\n",
    "        coeffs_features = calc_coeffs_features(coeffs)\n",
    "        wavelet_features.update({f\"{i}_{k}\": v for k, v in coeffs_features.items()})\n",
    "    \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbbd7296b02baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_band_power(channel_data, sfreq=SAMPLING_FREQ, n_fft=256) -> dict[str, float]:\n",
    "    frequency_bands = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 7),\n",
    "        \"alpha\": (7, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 50)\n",
    "    }\n",
    "\n",
    "    band_powers = {}\n",
    "\n",
    "    n_fft = min(n_fft, channel_data.shape[-1])\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(channel_data, sfreq=sfreq, n_fft=n_fft, fmin=0.5, fmax=50)\n",
    "\n",
    "    # Calculate power within each frequency band\n",
    "    for band, (fmin, fmax) in frequency_bands.items():\n",
    "        # Find indices of frequencies within the band\n",
    "        band_indices = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "\n",
    "        # Sum the power spectral density values within the band\n",
    "        band_power = np.sum(psds[band_indices])\n",
    "\n",
    "        band_powers[band] = band_power\n",
    "\n",
    "    return band_powers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9161530113c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_power_ratios(band_powers : dict[str, float]) -> dict[str, float]:\n",
    "    alpha_beta_ratio = band_powers[\"alpha\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_beta_ratio = band_powers[\"theta\"] / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / band_powers[\"beta\"] if band_powers[\"beta\"] != 0 else np.nan\n",
    "    theta_alpha_beta_alpha_ratio = (band_powers[\"theta\"] + band_powers[\"alpha\"]) / (band_powers[\"beta\"] + band_powers[\"alpha\"]) if (band_powers[\"beta\"] + band_powers[\"alpha\"]) != 0 else np.nan\n",
    "    alpha_theta_ratio = band_powers[\"alpha\"] / band_powers[\"theta\"] if band_powers[\"theta\"] != 0 else np.nan\n",
    "    theta_alpha_ratio = band_powers[\"theta\"] / band_powers[\"alpha\"] if band_powers[\"alpha\"] != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        \"alpha_beta_ratio\": alpha_beta_ratio,\n",
    "        \"theta_beta_ratio\": theta_beta_ratio,\n",
    "        \"theta_alpha_beta_ratio\": theta_alpha_beta_ratio,\n",
    "        \"theta_alpha_beta_alpha_ratio\": theta_alpha_beta_alpha_ratio,\n",
    "        \"alpha_theta_ratio\": alpha_theta_ratio,\n",
    "        \"theta_alpha_ratio\": theta_alpha_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a304d0cefaf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_band_powers(band_powers):\n",
    "    avg_band_powers = {}\n",
    "    for band in band_powers[0].keys():\n",
    "        avg_band_powers[band] = np.mean([bp[band] for bp in band_powers])\n",
    "        \n",
    "    return avg_band_powers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e45a45454716d",
   "metadata": {},
   "source": [
    "\n",
    "### pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfbf75e5c37dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_powerline_noise(raw):\n",
    "    powerline_noises = [50, 60]\n",
    "\n",
    "    for freq in powerline_noises:\n",
    "        raw.notch_filter(freqs=freq)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a4116df678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(patient_id):\n",
    "    corrupted = []\n",
    "    windows = []\n",
    "    \n",
    "    # output directory\n",
    "    #seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"seizure\")\n",
    "    #non_seizure_output_dir = os.path.join(OUTPUT_PATH, patient_id, \"non_seizure\")\n",
    "    #os.makedirs(seizure_output_dir, exist_ok=True)\n",
    "    #os.makedirs(non_seizure_output_dir, exist_ok=True)\n",
    "    \n",
    "    patient_events = data[data[\"patient_id\"] == patient_id]\n",
    "    recordings = patient_events.groupby(\"recording_path\")\n",
    "    \n",
    "    for recording_path, events in recordings:\n",
    "        raw = mne.io.read_raw_edf(recording_path, preload=True).pick(picks=CHANNELS)\n",
    "        \n",
    "        # sometimes meas date is corrupted/missing\n",
    "        raw.set_meas_date(None)\n",
    "        \n",
    "        # resample to desired sampling frequency\n",
    "        raw.resample(SAMPLING_FREQ)\n",
    "        \n",
    "         # Apply a bandpass filter to remove noise\n",
    "        raw.filter(0.5, 60)\n",
    "        \n",
    "        # remove powerline noise\n",
    "        raw = remove_powerline_noise(raw)\n",
    "        \n",
    "        events_onsets = events[\"onset\"].values\n",
    "        events_durations = events[\"duration\"].values\n",
    "        events_labels = events[\"label\"].values\n",
    "        \n",
    "        # create annotations\n",
    "        annotations = mne.Annotations(onset=events_onsets, duration=events_durations, description=events_labels)\n",
    "        raw.set_annotations(annotations)\n",
    "        \n",
    "        for _, event in events.iterrows():\n",
    "            patient_id = event[\"patient_id\"]\n",
    "            onset = event[\"onset\"]\n",
    "            duration = event[\"duration\"]\n",
    "            label = event[\"label\"]\n",
    "            \n",
    "            min_windows = int(duration / WINDOW_LENGTH)\n",
    "            \n",
    "            if min_windows == 0:\n",
    "                continue\n",
    "                \n",
    "            if onset + duration > raw.times[-1]:\n",
    "                if onset + duration - 1/SAMPLING_FREQ == raw.times[-1]:\n",
    "                    raw_event = raw.copy().crop(onset, raw.times[-1], include_tmax=True)\n",
    "                else:\n",
    "                    print(\"Corrupted annotation\", patient_id, event[\"session_id\"], event[\"recording_id\"])\n",
    "                    corrupted.append((patient_id, event[\"session_id\"], event[\"recording_id\"]))\n",
    "                    continue\n",
    "            else:\n",
    "                raw_event = raw.copy().crop(onset, onset + duration, include_tmax=False)\n",
    "                \n",
    "            epochs = mne.make_fixed_length_epochs(raw_event, duration=WINDOW_LENGTH, overlap=OVERLAP, preload=True)\n",
    "            \n",
    "            for epoch in epochs:\n",
    "                channels = epochs.info[\"ch_names\"]\n",
    "                \n",
    "                epoch_features = {}\n",
    "                band_powers = []\n",
    "                \n",
    "                for i, channel in enumerate(channels):\n",
    "                    channel_data = epoch[i]\n",
    "                    \n",
    "                    # normalize channel data using min-max scaling\n",
    "                    channel_data = (channel_data - np.min(channel_data)) / (np.max(channel_data) - np.min(channel_data))\n",
    "                    \n",
    "                    wavelet_features = extract_wavelet_features(channel_data)\n",
    "                    band_power = extract_band_power(channel_data)\n",
    "                    \n",
    "                    for key, value in wavelet_features.items():\n",
    "                        epoch_features[f\"{channel}_{key}\"] = value\n",
    "                    \n",
    "                    band_powers.append(band_power)\n",
    "                \n",
    "                avg_band_powers = calc_avg_band_powers(band_powers)\n",
    "                power_ratios = calc_power_ratios(avg_band_powers)\n",
    "                \n",
    "                epoch_features[\"label\"] = label\n",
    "                epoch_features[\"patient_id\"] = patient_id\n",
    "                epoch_features = {**epoch_features, **avg_band_powers, **power_ratios}\n",
    "                windows.append(epoch_features)\n",
    "                \n",
    "            #output_dir = seizure_output_dir if label == \"seiz\" else non_seizure_output_dir\n",
    "            #file_name = f\"{patient_id}_{event['session_id']}_{event[\"recording_id\"]}_{i}_epo.fif\"\n",
    "            #epochs.save(os.path.join(output_dir, file_name), overwrite=True)\n",
    "            raw_event.close()\n",
    "            \n",
    "        raw.close()\n",
    "        \n",
    "    return pd.DataFrame(windows), corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c4b68d79d2fc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a13acdf6d8fd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data[\"patient_id\"].unique()\n",
    "patients = patients[:5]\n",
    "extracted_features = []\n",
    "corrupted = []\n",
    "for patient in patients:\n",
    "    features, corrupted = preprocess(patient)\n",
    "    extracted_features.append(features)\n",
    "    corrupted.extend(corrupted)\n",
    "    \n",
    "extracted_features = pd.concat(extracted_features)\n",
    "extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ea0a3940b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features[\"patient_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb849059b064f23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
