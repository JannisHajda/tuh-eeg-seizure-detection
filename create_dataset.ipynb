{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630882e1442cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, session_id, recording_id, seizure):\n",
    "        self.session_id = session_id\n",
    "        self.recording_id = recording_id\n",
    "        self.seizure = seizure\n",
    "    \n",
    "class Patient:\n",
    "    def __init__(self, patient_id, samples: [Sample]):\n",
    "        self.patient_id = patient_id\n",
    "        self.samples = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6325700865052",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_PATH = \"/Users/jannis/Git/tuh-eeg-seizure-detection/data/preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb09f4430ae0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    patients = []\n",
    "    for patient in os.listdir(PREPROCESSED_PATH):\n",
    "        patient_path = os.path.join(PREPROCESSED_PATH, patient)\n",
    "        \n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "            \n",
    "        samples = []\n",
    "        \n",
    "        for non_seizure_sample in os.listdir(os.path.join(patient_path, \"non_seizures\")):\n",
    "            non_seizure_sample_path = os.path.join(patient_path, \"non_seizures\", non_seizure_sample)\n",
    "            \n",
    "            if not os.path.isfile(non_seizure_sample_path) or not non_seizure_sample.endswith(\".fif\"):\n",
    "                continue\n",
    "                \n",
    "            parts = non_seizure_sample.split(\"_\")\n",
    "            session_id = parts[0] + \"_\" + parts[1]\n",
    "            recording_id = parts[2]\n",
    "            sample = Sample(session_id, recording_id, False)\n",
    "            samples.append(sample)\n",
    "        \n",
    "        for seizure_sample in os.listdir(os.path.join(patient_path, \"seizures\")):\n",
    "            seizure_sample_path = os.path.join(patient_path, \"seizures\", seizure_sample)\n",
    "            \n",
    "            if not os.path.isfile(seizure_sample_path) or not seizure_sample.endswith(\".fif\"):\n",
    "                continue\n",
    "                \n",
    "            parts = seizure_sample.split(\"_\")\n",
    "            session_id = parts[0] + \"_\" + parts[1]\n",
    "            recording_id = parts[2]\n",
    "            sample = Sample(session_id, recording_id, True)\n",
    "            samples.append(sample)\n",
    "            \n",
    "        if len(samples) > 0:\n",
    "            patient = Patient(patient, samples)\n",
    "            patients.append(patient)\n",
    "        \n",
    "    \n",
    "    return patients\n",
    "\n",
    "load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af983dfad1a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "groups = []\n",
    "\n",
    "# Assuming load_preprocessed_data() loads your preprocessed data\n",
    "for patient in load_preprocessed_data():\n",
    "    for sample in patient.samples:\n",
    "        x.append(sample.session_id + \"_\" + sample.recording_id)\n",
    "        y.append(sample.seizure)\n",
    "        groups.append(patient.patient_id)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "groups = np.array(groups)\n",
    "\n",
    "# Set up StratifiedGroupKFold with 5 splits \n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate the splits\n",
    "splits = list(cv.split(x, y, groups))\n",
    "\n",
    "# Randomly choose one split for test\n",
    "test_fold_idx = np.random.choice(len(splits))\n",
    "\n",
    "# Get the train and test indices\n",
    "train_idx, test_idx = splits[test_fold_idx]\n",
    "\n",
    "# Split the data\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_test, y_test = x[test_idx], y[test_idx]\n",
    "\n",
    "# Get the number of positive/negative samples in both train and test and their ratio\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_ratio = counts[1] / counts[0]\n",
    "print(f\"Train - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Train ratio: {train_ratio}\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_ratio = counts[1] / counts[0]\n",
    "print(f\"Test - Unique: {unique} Counts: {counts}\")\n",
    "print(f\"Test ratio: {test_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581881093b097dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a623e02b36e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
