{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_dl_config\n",
    "import xarray as xr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_dl_config()\n",
    "\n",
    "INPUT_FILE = conf['input_file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TUHDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # data needs to be unsqueezed to add window dimension\n",
    "        return self.data[idx].unsqueeze(0), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataarray(INPUT_FILE)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare labels\n",
    "unique_labels = np.unique(data['label'].values)\n",
    "labels_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "labels = np.array([labels_map[label] for label in data['label'].values])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data['patient_id'].values\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data using stratifiedgroupkfold\n",
    "n_splits = 5\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "splits = list(sgkf.split(data, labels, groups))\n",
    "\n",
    "# select one split -> 80% train, 20% test\n",
    "train_idx, test_idx = splits[np.random.choice(n_splits)]\n",
    "\n",
    "train_data, train_labels = data[train_idx], labels[train_idx]\n",
    "test_data, test_labels = data[test_idx], labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TUHDataset(train_data, train_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TUHDataset(test_data, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition and training of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=1)  # Input channels = 1, Output channels = 6\n",
    "        # Mean Pooling Layer\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)  # Mean pooling with kernel size 2x2\n",
    "        \n",
    "        # Calculate the flattened size for the fully connected layer\n",
    "        # Input size: (batch_size, 1, 19, 5250)\n",
    "        # After conv1: (batch_size, 6, (19-5+1)=15, (5250-5+1)=5246)\n",
    "        # After pool: (batch_size, 6, 15//2=7, 5246//2=2623)\n",
    "        self.fc_input_size = 6 * 7 * 2623\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 1)  # Assuming binary classification: seizure vs. non-seizure\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid activation for binary classification\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EEGNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, labels in train_dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs.squeeze(), labels)  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += ((outputs.squeeze() > 0.5) == labels).sum().item()\n",
    "        \n",
    "    loss = running_loss/len(train_dataloader)\n",
    "    accurcay = correct/total\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss}, Accuracy: {accurcay}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
